{
  "p": [
    "MAPREDUCE-5512",
    "TaskTracker hung after failed reconnect to the JobTracker"
  ],
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "TaskTracker(TT): slave (client-side) JobTracker(JT): master (server-side)"
      ]
    },
    "(1.2) Symptoms (based on TT’s logs)": {
      "p": [
        "✦ 2013-09-08 04:20:48,441 ERROR org.apache.hadoop.mapred.TaskTracker: Caught exception: java.io.IOException: Call to jobtrackerhost/100.70.178.36:9010 failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host",
        "at org.apache.hadoop.ipc.Client.wrapException(Client.java:1155)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1123)",
        "at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)",
        "at org.apache.hadoop.mapred.$Proxy5.heartbeat(Unknown Source)",
        "at org.apache.hadoop.mapred.TaskTracker.transmitHeartBeat(TaskTracker.java:2038)",
        "at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1832)",
        "at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2685)",
        "at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3950)",
        "Caused by: java.io.IOException: An existing connection was forcibly closed by the remote host",
        "at sun.nio.ch.SocketDispatcher.read0(Native Method)",
        "at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)",
        "at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)",
        "at sun.nio.ch.IOUtil.read(IOUtil.java:198)",
        "at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)",
        "at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)",
        "at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)",
        "at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)",
        "at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)",
        "at java.io.FilterInputStream.read(FilterInputStream.java:133)",
        "at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:370)",
        "at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)",
        "at java.io.BufferedInputStream.read(BufferedInputStream.java:254)",
        "at java.io.DataInputStream.readInt(DataInputStream.java:387)",
        "at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:852)",
        "at org.apache.hadoop.ipc.Client$Connection.run(Client.java:797)",
        "✦ 2013-09-08 04:20:48,441 INFO org.apache.hadoop.mapred.TaskTracker: Resending 'status' to 'jobtrackerhost' with reponseId ‘-27775’”"
      ],
      "(if the last heartbeat got through, resend the previous status information)": {
        "p": [
          "✦ 2013-09-08 04:21:09,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: jobtrackerhost/100.70.178.36:9010. Already tried 0 time(s); maxRetries=45",
          "...",
          "2013-09-08 04:22:12,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: jobtrackerhost/100.70.178.36:9010. Already tried 3 time(s); maxRetries=45",
          "✦ 2013-09-08 04:22:21,723 INFO org.apache.hadoop.mapred.TaskTracker: Recieved ReinitTrackerAction from JobTracker(now, TT: State.STALE)",
          "",
          "✦ 2013-09-08 04:22:21,801 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Cleanup...",
          "java.lang.InterruptedException: sleep interrupted",
          "at java.lang.Thread.sleep(Native Method)",
          "atorg.apache.hadoop.filecache.TrackerDistributedCacheManager$CleanupThread.run (TrackerDistributedCacheManager.java:1038)",
          "✦ 2013-09-08 04:22:21,801 INFO org.apache.hadoop.mapred.TaskTracker: Shutting down: Map-events fetcher for all reduce tasks on tracker_workernode0:127.0.0.1/127.0.0.1:63692",
          "2013-09-08 04:22:21,801 INFO org.apache.hadoop.ipc.Server: Stopping server on 63692",
          "...",
          "✦ 2013-09-08 04:22:21,801 WARN org.apache.hadoop.mapred.TaskTracker: Reinitializing local state",
          "2013-09-08 04:22:21,833 INFO org.apache.hadoop.mapred.TaskTracker: Starting tasktracker with owner as hdp",
          "2013-09-08 04:22:21,833 INFO org.apache.hadoop.mapred.TaskTracker: Good mapred local directories are: c:\\hdfs\\mapred\\local",
          "...",
          "2013-09-08 04:22:21,833 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 63692: exiting",
          "...",
          "2013-09-08 04:22:21,833 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 63692: exiting",
          "...",
          "✦ 2013-09-08 04:22:21,864 INFO org.apache.hadoop.mapred.TaskTracker: TaskTracker up at: 127.0.0.1/127.0.0.1:62593",
          "✦2013-09-08 04:22:21,864 INFO org.apache.hadoop.mapred.TaskTracker: Starting tracker tracker_workernode0:127.0.0.1/127.0.0.1:62593(Then initialize DistributedCache)",
          "2013-09-08 04:22:21,864 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting",
          "...",
          "✦ 2013-09-08 04:22:22,208 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hdp cause:java.io.IOException: Call to jobtrackerhost/100.70.178.36:9010 failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host",
          "2013-09-08 04:22:22,223 ERROR org.apache.hadoop.mapred.TaskTracker: Got fatal exception while reinitializing TaskTracker: java.io.IOException: Call to jobtrackerhost/100.70.178.36:9010 failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host",
          "at org.apache.hadoop.ipc.Client.wrapException(Client.java:1155)",
          "at org.apache.hadoop.ipc.Client.call(Client.java:1123)",
          "at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)",
          "at org.apache.hadoop.mapred.$Proxy5.getProtocolVersion(Unknown Source)",
          "at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)",
          "at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:414)",
          "at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:392)",
          "at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:374)",
          "at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:453)",
          "at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:335)",
          "at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:300)",
          "at org.apache.hadoop.mapred.TaskTracker$3.run(TaskTracker.java:916)",
          "at java.security.AccessController.doPrivileged(Native Method)",
          "at javax.security.auth.Subject.doAs(Subject.java:415)",
          "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1233)",
          "at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java:912)",
          "at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2713)",
          "at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3950)",
          "Caused by: java.io.IOException: An existing connection was forcibly closed by the remote host",
          "at sun.nio.ch.SocketDispatcher.read0(Native Method)",
          "at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)",
          "at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)",
          "at sun.nio.ch.IOUtil.read(IOUtil.java:198)",
          "at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)",
          "at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)",
          "at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)",
          "at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)",
          "at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)",
          "at java.io.FilterInputStream.read(FilterInputStream.java:133)",
          "at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:370)",
          "at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)",
          "at java.io.BufferedInputStream.read(BufferedInputStream.java:254)",
          "at java.io.DataInputStream.readInt(DataInputStream.java:387)",
          "at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:852)",
          "at org.apache.hadoop.ipc.Client$Connection.run(Client.java:797)"
        ]
      }
    }
  },
  "(2) Root Cause": {
    "p": [
      "The operation “RPC.waitForProxy” in initialize() is trying to connect JobTracker. When the connection is closed by JT, it throws exception. This exception is caught by catch block in TT.run(), and “return;”. So TT will not try to connect JT anymore, and the methods close() or shutdown() in TT.run() will not execute. Since “distributedCacheManager.stopCleanupThread();” is in method close(), this cleanupThread in TT(TT is a process)will not stop. This TT cannot exit normally (if non-daemon thread exists, jvm will not exit), neither will be killed or restarted automatically.",
      "Note: close() will also be called in shutdown()",
      "",
      "offerService() {",
      "while() {",
      "try { …",
      "// Send the heartbeat and process the jobtracker's directives",
      "HeartbeatResponse heartbeatResponse = transmitHeartBeat(now);",
      "…",
      "Resending 'status' to 'jobtrackerhost' with reponseId ‘-27775’”",
      "TaskTrackerAction[] actions = heartbeatResponse.getActions();",
      "if (reinitTaskTracker(actions)) {",
      "return State.STALE;",
      "}",
      "…TaskTracker: Recieved ReinitTrackerAction from JobTracker",
      "} catch() { …… }",
      "catch() { “Caught exception:……” }",
      "}",
      "}",
      "",
      "TT.run() { try { …",
      "while(…){ while(…) { //This while-loop attempts reconnects if we get network errors",
      "…",
      "State osState = offerService();// it communicates with JT at intervals, with Heartbeat",
      "…",
      "}",
      "…",
      "LOG.warn(\"Reinitializing local state\");",
      "initialize();",
      "}",
      "if() { shutdown(); }",
      "} catch (IOException iex) { LOG.error(\"Got fatal exception while reinitializing TaskTracker: \" + StringUtils.stringifyException(iex));",
      "return;",
      "}",
      "}",
      "initialize() { …….",
      "// Initialize DistributedCache",
      "new TrackerDistributedCacheManager();",
      "this.distributedCacheManager.startCleanupThread();",
      "",
      "this.jobClient = (InterTrackerProtocol) UserGroupInformation.getLoginUser().doAs(",
      "new PrivilegedExceptionAction<Object>() {",
      "public Object run() throws IOException {",
      "return RPC.waitForProxy(...);",
      "}",
      "});",
      "…….",
      "}",
      "//Close down the TaskTracker and all its components. We must also shut down any running tasks or",
      "//threads, and cleanup disk space. A new TaskTracker within the same process space might be restarted, so",
      "//everything must be clean",
      "",
      "TT’s close() { …….",
      "this.distributedCacheManager.stopCleanupThread();",
      "…….",
      "}"
    ]
  },
  "(3) How to figure out the root cause based on logs": {
    "(3.1)": {
      "p": [
        "According to the log file, there are two sites which contain both error info and exception. They are both reported by TaskTracker. And they have the same error info, which is",
        "“java.io.IOException: Call to jobtrackerhost/100.70.178.36:9010 failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host”.",
        "After the 1st exception, TT is still able to communicate with JT, and receives “ReinitTrackerAction” from JT. When the 2nd exception occurs, TT will not continue to work. So the 2nd exception is more important than the 1st one."
      ]
    },
    "(3.2)": {
      "p": [
        "Based on the 2nd exception and the call relationshipin “TaskTracker.java”, we know that the exception is resulted from “RPC.waitForProxy”, which tried to connect JT but failed.",
        "Call relationship:",
        "TT.run()",
        "",
        "initialize()",
        "{ …...",
        "// Initialize DistributedCache",
        "// get this.jobClient through “RPC.waitForProxy”",
        "……",
        "}",
        "Exception fragment:",
        "at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:335)",
        "at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:300)",
        "at org.apache.hadoop.mapred.TaskTracker$3.run(TaskTracker.java:916)",
        "at java.security.AccessController.doPrivileged(Native Method)",
        "at javax.security.auth.Subject.doAs(Subject.java:415)",
        "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1233)",
        "at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java:912)"
      ]
    },
    "(3.3)": {
      "p": [
        "This exception which resulted from the connection failure is inevitable, but it shouldn't affect TT’s running. Here, TT hung means TT cannot exit normally, neither will be killed or restarted automatically. So we need to find out the reason that restrains TT to work. To find out the specific thread which “blocks” TT, TT stack dump file is used (I neglected this file before).",
        "In the dump file, three threads meet the condition “state = BLOCKED && java.lang.Thread.sleep(long)”.",
        "Thread 43: (state = BLOCKED)",
        "- java.lang.Thread.sleep(long) @bci=0 (Interpreted frame)",
        "- org.apache.hadoop.filecache.TrackerDistributedCacheManager$CleanupThread.run() @bci=11, line=1038 (Interpreted frame)",
        "",
        "Thread 27: (state = BLOCKED)",
        "- java.lang.Thread.sleep(long) @bci=0 (Interpreted frame)",
        "- org.apache.hadoop.mapred.TaskTracker.taskCleanUp() @bci=71, line=521 (Compiled frame)",
        "- org.apache.hadoop.mapred.TaskTracker$1.run() @bci=4, line=498 (Compiled frame)",
        "- java.lang.Thread.run() @bci=11, line=722 (Interpreted frame)",
        "",
        "Thread 25: (state = BLOCKED)",
        "- java.lang.Thread.sleep(long) @bci=0 (Interpreted frame)",
        "- org.apache.hadoop.mapred.UserLogCleaner.run() @bci=4, line=93 (Interpreted frame)",
        "",
        "For thread 25, UserLogCleaner.run() doesn’t ’t have relation with TT, excluded.",
        "For thread 27, TaskTracker.taskCleanUp() is a deamon thread, so it will not prevent the TT to exit.",
        "For thread 43, TrackerDistributedCacheManager.CleanupThread.run() can’t be stopped, and it is non-deamon thread. So the JVM which running TT will not exit, i.e. TT will not exit normally, neither will it reconnect to JT."
      ]
    }
  },
  "(4) Fixing Method": {
    "p": [
      "Make the distributed cache cleanup thread a daemon in file “src/mapred/org/apache/hadoop/filecache/TrackerDistributedCacheManager.java”."
    ]
  },
  "(5) How many nodes are involved in the patch? (multiple/single node(s))": {
    "p": [
      "Only “TrackerDistributedCacheManager.java” really matters the root cause. The other modifications may be convenient for debugging. “MiniMRCluster.java” is used to test mapreduce locally and simulate map-reduce cluster.",
      "• src/core/org/apache/hadoop/http/HttpServer.java;",
      "-webServer.setThreadPool(new QueuedThreadPool());",
      "+QueuedThreadPool threadPool = new QueuedThreadPool();",
      "+ threadPool.setName(\"httpServerThreadPool\");",
      "+ webServer.setThreadPool(threadPool);",
      "",
      "• src/mapred/org/apache/hadoop/filecache/TrackerDistributedCacheManager.java;",
      "this.cleanupThread = new CleanupThread(conf);",
      "+ this.cleanupThread.setName(\"distCacheManagerCleanupThread\");",
      "+ this.cleanupThread.setDaemon(true);",
      "",
      "• src/mapred/org/apache/hadoop/mapred/JobEndNotifier.java;",
      "LOG.error(\"Notification failure [\" + notification + \"]\", ex);",
      "}",
      "}",
      "- });",
      "+ }, \"jobEndNotifier\");",
      "",
      "• src/test/org/apache/hadoop/mapred/MiniMRCluster.java",
      "- jobTrackerThread = new Thread(jobTracker);",
      "+ jobTrackerThread = new Thread(jobTracker, \"jobTrackerMain\");",
      "- Thread taskTrackerThread = new Thread(taskTracker);",
      "+ Thread taskTrackerThread = new Thread(taskTracker, \"taskTrackerMain\");",
      "taskTrackerList.add(taskTracker);",
      ""
    ]
  }
}