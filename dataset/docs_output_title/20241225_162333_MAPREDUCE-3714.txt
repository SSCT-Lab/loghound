{
  "p": [
    "MAPREDUCE-3714",
    "Reduce hangs in a corner case"
  ],
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "reducer: client-side AM: server-side",
        "(1.2) Symptoms",
        "In the description “found this long time back and we(Sid/I) ran into this again.”",
        "The log and hanging reducers’ thread dump below are totally the same as those in mr-3226.",
        "exception in reducer log:",
        "2011-10-18 10:34:41,006 INFO org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: hostname.com/$ip_addr\"; destination host is: \"\"hostname.com\":12345;",
        "at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:601)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1089)",
        "at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)",
        "at $Proxy6.statusUpdate(Unknown Source)",
        "at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:671)",
        "at java.lang.Thread.run(Thread.java:619)",
        "Caused by: java.nio.channels.ClosedByInterruptException",
        "at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)",
        "at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)",
        "at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:60)",
        "at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)",
        "at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:151)",
        "at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:112)",
        "at org.apache.hadoop.security.SaslOutputStream.write(SaslOutputStream.java:168)",
        "at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)",
        "at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)",
        "at java.io.DataOutputStream.flush(DataOutputStream.java:106)",
        "at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:796)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1066)",
        "at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)",
        "at $Proxy6.getMapCompletionEvents(Unknown Source)",
        "at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents(EventFetcher.java:99)",
        "at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:65)",
        "And it has the following thread dump:",
        "\"EventFetcher for fetching Map Completion Events\"daemon prio=10 tid=0xa325fc00 nid=0x1ca4 waiting on condition [0xa315c000]",
        "java.lang.Thread.State: TIMED_WAITING (sleeping)",
        "at java.lang.Thread.sleep(Native Method)",
        "at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:71)",
        "",
        "\"main\"prio=10 tid=0x080ed400 nid=0x1c71 in Object.wait() [0xf73a2000]",
        "java.lang.Thread.State: WAITING (on object monitor)",
        "at java.lang.Object.wait(Native Method)",
        "- waiting on <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)",
        "at java.lang.Thread.join(Thread.java:1143)",
        "- locked <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)",
        "at java.lang.Thread.join(Thread.java:1196)",
        "at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:135)",
        "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:367)",
        "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)",
        "at java.security.AccessController.doPrivileged(Native Method)",
        "at javax.security.auth.Subject.doAs(Subject.java:396)",
        "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)",
        "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)",
        ""
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "The log and hanging reducers’ thread dump below are totally the same as those in mr-3226.",
      "Please refer to part (2) in mr-3226."
    ]
  },
  "(3) Root Cause": {
    "p": [
      "When current thread (eventFetcher) is executing method sleep/wait/join, eventFetcher.interrupt() will make it throw InterruptedException immediately.",
      ""
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "“fixing the root cause”",
      "The patch is to fixing EventFetcher and Fetcher threads to shut-down properly.",
      "•hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java",
      "",
      "+private volatile booleanstopped= false;Add a member variable in Class EventFetcher, used in the condition of while loop and newly-added shutDown().",
      "",
      "In eventFetcher.run() :",
      "public voidrun() {",
      "intfailures = 0;",
      "LOG.info(reduce+\"Threadstarted: \"+ getName());",
      "try{",
      "-while (true && !Thread.currentThread().isInterrupted())",
      "+while(!stopped&& !Thread.currentThread().isInterrupted()) {",
      "try{",
      "intnumNewMaps =getMapCompletionEvents();",
      "failures = 0;",
      "if(numNewMaps > 0) {LOG.info(reduce+\": \"+\"Got\"+ numNewMaps +\"new map-outputs\"); }",
      "LOG.debug(\"GetMapEventsThread about to sleep for\"+SLEEP_TIME);",
      "if(!Thread.currentThread().isInterrupted()) {",
      "Thread.sleep(SLEEP_TIME);",
      "}",
      "+} catch (InterruptedException e) {handle the case when current thread is doing some “common” operations like assignment, for, whie, if , etc.",
      "+LOG.info(\"EventFetcher is interrupted.. Returning\");",
      "+return;",
      "} catch(IOException ie) {",
      "LOG.info(\"Exception in getting events\", ie);",
      "// check to see whether to abort",
      "if(++failures >=MAX_RETRIES) {",
      "throw newIOException(\"too many failures downloading events\", ie);",
      "}",
      "// sleep for a bit",
      "if(!Thread.currentThread().isInterrupted()) {",
      "Thread.sleep(RETRY_PERIOD);",
      "}",
      "}//catch",
      "}//while",
      "}catch(InterruptedException e) {return;",
      "}catch(Throwable t) {exceptionReporter.reportException(t);return; }",
      "}",
      "",
      "",
      "+public voidshutDown() {This method is called in shuffle.run, to replace the original eventFetcher.interrupt() & join()",
      "+this.stopped= true;",
      "+interrupt();",
      "",
      "",
      "+try {",
      "+join(5000);Set a time limit for join()",
      "+} catch(InterruptedException ie) {",
      "+LOG.warn(\"Got interrupted while joining \" + getName(), ie);",
      "+}",
      "+}",
      "",
      "A similar fix is applied in fetcher thread.",
      "•hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "",
      "+private volatile booleanstopped= false;Add a member variable in Class Fetcher, used in the condition of while loop and newly-added shutDown().",
      "",
      "",
      "In Fetcher.run():",
      "public void run() {",
      "try {",
      "-while (true && !Thread.currentThread().isInterrupted()) {",
      "+while (!stopped&& !Thread.currentThread().isInterrupted()) {",
      "MapHost host = null;",
      "try {",
      "// If merge is on, block",
      "",
      "",
      "",
      "+public voidshutDown() throws InterruptedException {This method is called in shuffle.run, to replace the origianl fetcher.interrupt() & join().",
      "",
      "+this.stopped = true;",
      "+interrupt();",
      "+try {",
      "+join(5000);",
      "+} catch (InterruptedException ie) {",
      "+LOG.warn(\"Got interrupt while joining \" + getName(), ie);",
      "+}",
      "+}",
      "+",
      "",
      "The patch also fixes shuffle.run()",
      "•hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "publicRawKeyValueIteratorrun()throwsIOException, InterruptedException {",
      "//Start the map-completion events fetcher thread",
      "finalEventFetcher<K,V> eventFetcher =newEventFetcher<K,V>(reduceId, umbilical, scheduler,this);",
      "eventFetcher.start();",
      "",
      "//Start the map-output fetcher threads",
      "final intWritableRpcEngine.java =jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES,5);",
      "Fetcher<K,V>[] fetchers =newFetcher[numFetchers];",
      "for(inti=0; i < numFetchers; ++i) {",
      "fetchers[i] =newFetcher<K,V>(jobConf, reduceId, scheduler, merger, reporter, metrics, this,",
      "reduceTask.getJobTokenSecret());",
      "fetchers[i].start();",
      "}",
      "//Wait for shuffle to complete successfully",
      "while(!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {",
      "reporter.progress();",
      "synchronized(this) {",
      "if(throwable!=null) {",
      "throw newShuffleError(\"error in shuffle in \"+throwingThreadName,throwable);",
      "}",
      "}",
      "}",
      "",
      "",
      "",
      "//Stop the event-fetcher thread",
      "-eventFetcher.interrupt();using the newly-added shutDown()",
      "-try{",
      "-eventFetcher.join();",
      "-}catch(Throwable t) {LOG.info(\"Failed to stop \"+ eventFetcher.getName(), t); }",
      "+eventFetcher.shutDown();",
      "",
      "//Stop the map-output fetcher threads",
      "for(Fetcher<K,V> fetcher : fetchers) {",
      "-fetcher.interrupt();",
      "-}",
      "-for(Fetcher<K,V> fetcher : fetchers) {",
      "-fetcher.join();",
      "+fetcher.shutDown();",
      "}",
      "fetchers =null;",
      "……",
      "}",
      ""
    ]
  },
  "(5) How many nodes are involved in the patch? (multiple/single node(s))": {
    "p": [
      "The event fetcher thread and fetcher thread are both used in shuffle phase of reduce task, and the fixes are applied on reducer(s).",
      ""
    ]
  }
}