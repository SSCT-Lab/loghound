{
  "p": [
    "MAPREDUCE-4842",
    "Shuffle race can hang reducer"
  ],
  "(1) Log information": {
    "p": [
      "This bug is duplicated bymapreduce-5423, so we use the log from mapreduce-5423 to analyze this bug.",
      "The logs are from reducers.",
      "2013-07-18 04:32:57,900 INFO fetcher#4 org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergerManager returned Status.WAIT ...",
      "...",
      "2013-07-18 04:32:57,904 INFO fetcher#3 org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergerManager returned Status.WAIT ...",
      ""
    ]
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "The above log entries are printed in Fetcher.copyMapOutput():",
      "",
      "privateTaskAttemptID[]copyMapOutput(...) { Fetcher.java",
      "MapOutput<K,V> mapOutput =null;",
      "...",
      "try{",
      "...",
      "// Get the location for the map output - either in-memory or on-disk",
      "mapOutput =merger.reserve(mapId, decompressedLength,id);",
      "",
      "// Check if we can shuffle *now* ...",
      "if(mapOutput.getType() == Type.WAIT) {",
      "LOG.info(\"fetcher#\"+id+\" - MergerManager returnedStatus.WAIT...\");",
      "//Not an error but wait to process data.",
      "returnEMPTY_ATTEMPT_ID_ARRAY;",
      "}",
      "// Go!",
      "LOG.info(\"fetcher#\"+id+\" about to shuffle output of map \"+",
      "mapOutput.getMapId() +\" decomp: \"+",
      "decompressedLength +\" len: \"+ compressedLength +\" to \"+",
      "mapOutput.getType());",
      "if(mapOutput.getType() == Type.MEMORY) {",
      "shuffleToMemory(host, mapOutput, input,",
      "(int) decompressedLength, (int) compressedLength);",
      "}else{",
      "shuffleToDisk(host, mapOutput, input, compressedLength);",
      "}",
      "",
      "// Inform the shuffle scheduler",
      "longendTime = System.currentTimeMillis();",
      "scheduler.copySucceeded(mapId, host, compressedLength,",
      "endTime - startTime, mapOutput);",
      "// Note successful shuffle",
      "remaining.remove(mapId);",
      "metrics.successFetch();",
      "return null;",
      "}catch(IOException ioe) {",
      "...",
      "}",
      "}",
      "",
      "Since mapOutput is returned by merger.reserve(), we can infer that usedMemory > memoryLimit",
      "public synchronizedMapOutput<K,V>reserve(...)throwsIOException { MergeManager.java",
      "",
      "if(!canShuffleToMemory(requestedSize)) {",
      "LOG.info(mapId +\": Shuffling to disk since \"+ requestedSize +",
      "\" is greater than maxSingleShuffleLimit (\"+maxSingleShuffleLimit+\")\");",
      "return newMapOutput<K,V>(mapId,this, requestedSize,jobConf,",
      "localDirAllocator, fetcher,true,mapOutputFile);",
      "}",
      "",
      "// Stall shuffle if we are above the memory limit",
      "",
      "// It is possible that all threads could just be stalling and not make",
      "// progress at all. This could happen when:",
      "//",
      "// requested size is causing the used memory to go above limit &&",
      "// requested size < singleShuffleLimit &&",
      "// current used size < mergeThreshold (merge will not get triggered)",
      "//",
      "// To avoid this from happening, we allow exactly one thread to go past",
      "// the memory limit. We check (usedMemory > memoryLimit) and not",
      "// (usedMemory + requestedSize > memoryLimit). When this thread is done",
      "// fetching, this will automatically trigger a merge thereby unlocking",
      "// all the stalled threads",
      "",
      "if(usedMemory>memoryLimit) {",
      "LOG.info(mapId +\": Stalling shuffle since usedMemory (\"+usedMemory",
      "+\") is greater than memoryLimit (\"+memoryLimit+\").\"+",
      "\" CommitMemory is (\"+commitMemory+\")\");",
      "returnstallShuffle;",
      "}",
      "...",
      "}",
      "",
      "public synchronized voidcloseInMemoryFile(MapOutput<K,V> mapOutput) { MergeManager.java",
      "inMemoryMapOutputs.add(mapOutput);",
      "LOG.info(\"closeInMemoryFile -> map-output of size: \"+ mapOutput.getSize()",
      "+\", inMemoryMapOutputs.size() -> \"+inMemoryMapOutputs.size()",
      "+\", commitMemory -> \"+commitMemory+\", usedMemory ->\"+usedMemory);",
      "",
      "commitMemory+= mapOutput.getSize();",
      "",
      "synchronized(inMemoryMerger) {",
      "// Can hang if mergeThreshold is really low.",
      "if(!inMemoryMerger.isInProgress() &&commitMemory>=mergeThreshold) {",
      "LOG.info(\"Starting inMemoryMerger's merge since commitMemory=\"+",
      "commitMemory+\" > mergeThreshold=\"+mergeThreshold+",
      "\". Current usedMemory=\"+usedMemory);",
      "inMemoryMapOutputs.addAll(inMemoryMergedMapOutputs);",
      "inMemoryMergedMapOutputs.clear();",
      "inMemoryMerger.startMerge(inMemoryMapOutputs);",
      "}",
      "}",
      "",
      "if(memToMemMerger!=null) {",
      "synchronized(memToMemMerger) {",
      "if(!memToMemMerger.isInProgress() &&",
      "inMemoryMapOutputs.size() >=memToMemMergeOutputsThreshold) {",
      "memToMemMerger.startMerge(inMemoryMapOutputs);",
      "}",
      "}",
      "}",
      "}",
      ""
    ]
  },
  "(3) Root Cause": {
    "p": [
      "If the memory freed by an in-memory merge does not bring MergeManager.usedMemory below MergeManager.memoryLimit, and all current Fetchers complete before the in-memory merge completes, another in-memory merge will not be triggered - and shuffle will hang. (All new fetchers are asked to WAIT)."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "Fixing the error.",
      "In MergeThread.run, re-check the condition and trigger another merge at the end of the merge itself.",
      "•hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/MergeThread.java",
      "- public synchronized boolean isInProgress() {",
      "- return inProgress;",
      "- }",
      "-",
      "- public synchronized void startMerge(Set<T> inputs) {",
      "+ public void startMerge(Set<T> inputs) {",
      "if (!closed) {",
      "- inProgress = true;",
      "- this.inputs = new ArrayList<T>();",
      "+ numPending.incrementAndGet();",
      "+ List<T> toMergeInputs = new ArrayList<T>();",
      "Iterator<T> iter=inputs.iterator();",
      "for (int ctr = 0; iter.hasNext() && ctr < mergeFactor; ++ctr) {",
      "- this.inputs.add(iter.next());",
      "+ toMergeInputs.add(iter.next());",
      "iter.remove();",
      "}",
      "- LOG.info(getName() + \": Starting merge with \" + this.inputs.size() +",
      "+ LOG.info(getName() + \": Starting merge with \" + toMergeInputs.size() +",
      "\" segments, while ignoring \" + inputs.size() + \" segments\");",
      "- notifyAll();",
      "+ synchronized(pendingToBeMerged) {",
      "+ pendingToBeMerged.addLast(toMergeInputs);",
      "+ pendingToBeMerged.notifyAll();",
      "+ }",
      "}",
      "}",
      "public synchronized void waitForMerge() throws InterruptedException {",
      "- while (inProgress) {",
      "+ while (numPending.get() > 0) {",
      "wait();",
      "}",
      "}",
      "public void run() {",
      "while (true) {",
      "+ List<T> inputs = null;",
      "try {",
      "// Wait for notification to start the merge...",
      "- synchronized (this) {",
      "- while (!inProgress) {",
      "- wait();",
      "+ synchronized (pendingToBeMerged) {",
      "+ while(pendingToBeMerged.size() <= 0) {",
      "+ pendingToBeMerged.wait();",
      "}",
      "+ // Pickup the inputs to merge.",
      "+ inputs = pendingToBeMerged.removeFirst();",
      "}",
      "// Merge",
      "merge(inputs);",
      "} catch (InterruptedException ie) {",
      "+ numPending.set(0);",
      "return;",
      "} catch(Throwable t) {",
      "+ numPending.set(0);",
      "reporter.reportException(t);",
      "return;",
      "} finally {",
      "synchronized (this) {",
      "- // Clear inputs",
      "- inputs = null;",
      "- inProgress = false;",
      "+ numPending.decrementAndGet();",
      "notifyAll();",
      "}",
      "}",
      "",
      "In MergeManager,",
      "•All calls to isInProgress() are removed.",
      "•Unnecessary synchronized clauses on merge thread objects are removed since the methods where they are in themselves are synchronized.",
      "•hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/MergeManager.java",
      "",
      "@@ -34,9 +34,9 @@ public class ContainerTokenSecretManager extends",
      "private static Log LOG = LogFactory",
      ".getLog(ContainerTokenSecretManager.class);",
      "- private Map<String, SecretKey> secretkeys =",
      "- new HashMap<String, SecretKey>();",
      "-",
      "+ Map<String, SecretKey>secretkeys=",
      "+ newConcurrentHashMap<String, SecretKey>();",
      "+",
      "// Used by master for generation of secretyKey per host",
      "public SecretKey createAndGetSecretKey(CharSequence hostName) {",
      "String hostNameStr = hostName.toString();",
      "",
      "@@ -85,7 +87,7 @@",
      "Set<MapOutput<K, V>> inMemoryMapOutputs =",
      "new TreeSet<MapOutput<K,V>>(new MapOutputComparator<K, V>());",
      "- private final InMemoryMerger inMemoryMerger;",
      "+ private final MergeThread<MapOutput<K,V>, K,V> inMemoryMerger;",
      "",
      "Set<Path> onDiskMapOutputs = new TreeSet<Path>();",
      "private final OnDiskMerger onDiskMerger;",
      "@@ -179,6 +181,8 @@",
      "+ singleShuffleMemoryLimitPercent);",
      "}",
      "+ usedMemory = 0L;",
      "+ commitMemory = 0L;",
      "this.maxSingleShuffleLimit =",
      "(long)(memoryLimit * singleShuffleMemoryLimitPercent);",
      "this.memToMemMergeOutputsThreshold =",
      "@@ -210,7 +214,7 @@",
      "this.memToMemMerger = null;",
      "}",
      "",
      "- this.inMemoryMerger = new InMemoryMerger(this);",
      "+ this.inMemoryMerger = createInMemoryMerger();",
      "this.inMemoryMerger.start();",
      "",
      "this.onDiskMerger = new OnDiskMerger(this);",
      "@@ -219,11 +223,19 @@",
      "this.mergePhase = mergePhase;",
      "}",
      "",
      "+ protected MergeThread<MapOutput<K,V>, K,V> createInMemoryMerger() {",
      "+ return new InMemoryMerger(this);",
      "+ }",
      "TaskAttemptID getReduceId() {",
      "return reduceId;",
      "}",
      "+ @VisibleForTesting",
      "+ ExceptionReporter getExceptionReporter() {",
      "+ return exceptionReporter;",
      "+ }",
      "+",
      "public void waitForInMemoryMerge() throws InterruptedException {",
      "inMemoryMerger.waitForMerge();",
      "}",
      "@@ -288,7 +300,6 @@",
      "}",
      "",
      "synchronized void unreserve(long size) {",
      "- commitMemory -= size;",
      "usedMemory -= size;",
      "}",
      "@@ -300,24 +311,20 @@",
      "commitMemory+= mapOutput.getSize();",
      "- synchronized (inMemoryMerger) {",
      "- // Can hang if mergeThreshold is really low.",
      "- if (!inMemoryMerger.isInProgress() && commitMemory >= mergeThreshold) {",
      "- LOG.info(\"Starting inMemoryMerger's merge since commitMemory=\" +",
      "- commitMemory + \" > mergeThreshold=\" + mergeThreshold +",
      "- \". Current usedMemory=\" + usedMemory);",
      "- inMemoryMapOutputs.addAll(inMemoryMergedMapOutputs);",
      "- inMemoryMergedMapOutputs.clear();",
      "- inMemoryMerger.startMerge(inMemoryMapOutputs);",
      "- }",
      "+ // Can hang if mergeThreshold is really low.",
      "+ if (commitMemory >= mergeThreshold) {",
      "+ LOG.info(\"Starting inMemoryMerger's merge since commitMemory=\" +",
      "+ commitMemory + \" > mergeThreshold=\" + mergeThreshold +",
      "+ \". Current usedMemory=\" + usedMemory);",
      "+ inMemoryMapOutputs.addAll(inMemoryMergedMapOutputs);",
      "+ inMemoryMergedMapOutputs.clear();",
      "+ inMemoryMerger.startMerge(inMemoryMapOutputs);",
      "+ commitMemory = 0L; // Reset commitMemory.",
      "}",
      "",
      "if (memToMemMerger != null) {",
      "- synchronized (memToMemMerger) {",
      "- if (!memToMemMerger.isInProgress() &&",
      "- inMemoryMapOutputs.size() >= memToMemMergeOutputsThreshold) {",
      "- memToMemMerger.startMerge(inMemoryMapOutputs);",
      "- }",
      "+ if (inMemoryMapOutputs.size() >= memToMemMergeOutputsThreshold) {",
      "+ memToMemMerger.startMerge(inMemoryMapOutputs);",
      "}",
      "}",
      "}",
      "@@ -333,11 +340,8 @@",
      "public synchronized void closeOnDiskFile(Path file) {",
      "onDiskMapOutputs.add(file);",
      "",
      "- synchronized (onDiskMerger) {",
      "- if (!onDiskMerger.isInProgress() &&",
      "- onDiskMapOutputs.size() >= (2 * ioSortFactor - 1)) {",
      "- onDiskMerger.startMerge(onDiskMapOutputs);",
      "- }",
      "+ if (onDiskMapOutputs.size() >= (2 * ioSortFactor - 1)) {",
      "+ onDiskMerger.startMerge(onDiskMapOutputs);",
      "}",
      "}",
      ""
    ]
  },
  "(5) How many nodes are involved in the patch": {
    "p": [
      "The patch will work on reducers."
    ]
  }
}