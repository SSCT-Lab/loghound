{
  "p": [
    "MAPREDUCE-5542",
    "Killing a job just as it finishes can generate an NPE in client"
  ],
  "(1) Log information": {
    "p": [
      "If a client tries to kill a job just as the job is finishing then the client can crash with an NPE。",
      "",
      "$ mapred job -kill job_1379617216746_0084",
      "13/09/26 14:38:46 INFO client.RMProxy: Connecting to ResourceManager at xx/xx:xx",
      "13/09/26 14:38:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=KILLED. Redirecting to job history server",
      "Exception in thread \"main\" java.lang.NullPointerException",
      "at org.apache.hadoop.mapred.YARNRunner.killJob(YARNRunner.java:563)",
      "at org.apache.hadoop.mapreduce.Job.killJob(Job.java:624)",
      "at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:299)",
      "at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)",
      "at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)",
      "at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1231)"
    ]
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "Based on the stack trace contained in the log, we see that the error happens when JobClient submitApplication to RM through RPC. Althogh the logs from JobClient are not provided, we can infer that the exception will also occur on JobClient.",
      "Combining the top frames of the stack trace and the source code, we can see the following call relationship. The ERROR and WARN are caused by the same error.",
      "",
      "in MRDelegationTokenRenewer.java",
      "public longrenew(Token<?> token, Configuration conf)throwsIOException, InterruptedException {",
      "...",
      "MRClientProtocol histProxy = instantiateHistoryProxy(conf,",
      "SecurityUtil.getTokenServiceAddr(token));",
      "try{",
      "RenewDelegationTokenRequest request = Records",
      ".newRecord(RenewDelegationTokenRequest.class);",
      "request.setDelegationToken(dToken);",
      "returnhistProxy.renewDelegationToken(request).getNextExpirationTime();",
      "}finally{",
      "stopHistoryProxy(histProxy);",
      "}",
      "}",
      "",
      "protected voidstopHistoryProxy(MRClientProtocol proxy) {",
      "RPC.stopProxy(proxy);",
      "}",
      "",
      "",
      "/**",
      "* Stop the proxy. Proxy must either implement {@linkCloseable} or must have",
      "* associated {@linkRpcInvocationHandler}.",
      "*/",
      "public static voidstopProxy(Object proxy) {in RPC.java",
      "if(proxy ==null) {",
      "throw newHadoopIllegalArgumentException(\"Cannot close proxy since it is null\");",
      "}",
      "try{",
      "if(proxyinstanceofCloseable) {",
      "((Closeable) proxy).close();",
      "return;",
      "}else{",
      "InvocationHandler handler = Proxy.getInvocationHandler(proxy);",
      "if(handlerinstanceofCloseable) {",
      "((Closeable) handler).close();",
      "return;",
      "}",
      "}",
      "}catch(IOException e) {",
      "LOG.error(\"Closing proxy or invocation handler caused exception\", e);",
      "}catch(IllegalArgumentException e) {",
      "LOG.error(\"RPC.stopProxy called on non proxy.\", e);",
      "}",
      "",
      "thrownewHadoopIllegalArgumentException(",
      "\"Cannot close proxy - is not Closeable or \"",
      "+\"does not provide closeable invocation handler \"",
      "+ proxy.getClass());",
      "}",
      "",
      "HSClientProtocolPBClientImpl should implement Closeable.",
      "Based on the stack trace and the source code, we know NPE occurs in YARNRunner.killJob():",
      "public voidkillJob(JobID arg0)throwsIOException, InterruptedException {YARNRunner.java",
      "/* check if the status is not running, if not send kill to RM */",
      "JobStatus status =clientCache.getClient(arg0).getJobStatus(arg0);",
      "+ApplicationId appId = TypeConverter.toYarn(arg0).getAppId();",
      "+",
      "+// get status from RM and return",
      "+if (status == null) {",
      "+killUnFinishedApplication(appId);",
      "+return;",
      "+}",
      "+",
      "if(status.getState() != JobStatus.State.RUNNING) {",
      "-try{",
      "-resMgrDelegate.killApplication(TypeConverter.toYarn(arg0).getAppId());",
      "-}catch(YarnException e) {",
      "-throw newIOException(e);",
      "-}",
      "+killApplication(appId);",
      "return;",
      "}",
      "",
      "try{",
      "/* send a kill to the AM */",
      "clientCache.getClient(arg0).killJob(arg0);ßBased on the printed INFO,we know this statement is executed",
      "longcurrentTimeMillis = System.currentTimeMillis();",
      "longtimeKillIssued = currentTimeMillis;",
      "while((currentTimeMillis < timeKillIssued +10000L) && (status.getState()",
      "!= JobStatus.State.KILLED)) {",
      "try{",
      "Thread.sleep(1000L);",
      "}catch(InterruptedException ie) {",
      "/** interrupted, just break */",
      "break;",
      "}",
      "currentTimeMillis = System.currentTimeMillis();",
      "status =clientCache.getClient(arg0).getJobStatus(arg0);",
      "}",
      "}catch(IOException io) {",
      "LOG.debug(\"Error when checking for application status\", io);",
      "}",
      "if(status.getState() != JobStatus.State.KILLED) {",
      "try{",
      "resMgrDelegate.killApplication(TypeConverter.toYarn(arg0).getAppId());",
      "}catch(YarnException e) {",
      "throw newIOException(e);",
      "}",
      "}",
      "}",
      "",
      "The above killJob() is as follows:",
      "public booleankillJob(JobID oldJobID)throwsIOException {ClientServiceDelegate.java",
      "org.apache.hadoop.mapreduce.v2.api.records.JobId jobId",
      "= TypeConverter.toYarn(oldJobID);",
      "KillJobRequest killRequest =recordFactory.newRecordInstance(KillJobRequest.class);",
      "killRequest.setJobId(jobId);",
      "invoke(\"killJob\", KillJobRequest.class, killRequest);",
      "return true;",
      "}",
      "",
      "invoke() will call the following getProxy() which returns historyServer.",
      "privateMRClientProtocolgetProxy()throwsIOException {",
      "if(realProxy!=null) {",
      "returnrealProxy;",
      "}",
      "...",
      "//History server can serve a job only if application",
      "//succeeded.",
      "if(application.getYarnApplicationState() == YarnApplicationState.FINISHED) {",
      "LOG.info(\"Application state is completed. FinalApplicationStatus=\"",
      "+ application.getFinalApplicationStatus().toString()",
      "+\". Redirecting to job history server\");",
      "realProxy= checkAndGetHSProxy(application, JobState.SUCCEEDED);",
      "}",
      "returnrealProxy;",
      "}"
    ]
  },
  "(3) Root Cause": {
    "p": [
      "Since the following log is printed,",
      "INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=KILLED. Redirecting to job history server",
      "we can infer that in YarnRunner.killJob(), when client gets job status from RM first, the status is running.",
      "However, before the “kill” command is sent to AM, AM exits and historyServer has no information for this job. Later on, when “kill” is sent to AM, the request will be redirected to historyServer which will returns null."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "Fixing the error.",
      "YARNRunner.killJob needs to check null result when it obtains the job status.",
      "If status is null, kill the app via YARN.",
      "•hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "",
      "+private voidkillUnFinishedApplication(ApplicationId appId)",
      "+throws IOException {",
      "+ApplicationReport application = null;",
      "+try {",
      "+application = resMgrDelegate.getApplicationReport(appId);",
      "+} catch (YarnException e) {",
      "+throw new IOException(e);",
      "+}",
      "+if (application.getYarnApplicationState() == YarnApplicationState.FINISHED",
      "+|| application.getYarnApplicationState() == YarnApplicationState.FAILED",
      "+|| application.getYarnApplicationState() == YarnApplicationState.KILLED) {",
      "+return;",
      "+}",
      "+killApplication(appId);",
      "+}",
      "+",
      "+private voidkillApplication(ApplicationId appId) throws IOException {",
      "+try {",
      "+resMgrDelegate.killApplication(appId);",
      "+} catch (YarnException e) {",
      "+throw new IOException(e);",
      "+}",
      "+}",
      "+",
      "+private booleanisJobInTerminalState(JobStatus status) {",
      "+return status.getState() == JobStatus.State.KILLED",
      "+|| status.getState() == JobStatus.State.FAILED",
      "+|| status.getState() == JobStatus.State.SUCCEEDED;",
      "+}",
      "+",
      "",
      "public voidkillJob(JobID arg0)throwsIOException, InterruptedException {YARNRunner.java",
      "/* check if the status is not running, if not send kill to RM */",
      "JobStatus status =clientCache.getClient(arg0).getJobStatus(arg0);",
      "+ApplicationId appId = TypeConverter.toYarn(arg0).getAppId();",
      "+",
      "+// get status from RM and return",
      "+if (status == null) {",
      "+killUnFinishedApplication(appId);",
      "+return;",
      "+}",
      "+",
      "if(status.getState() != JobStatus.State.RUNNING) {",
      "-try{",
      "-resMgrDelegate.killApplication(TypeConverter.toYarn(arg0).getAppId());",
      "-}catch(YarnException e) {",
      "-throw newIOException(e);",
      "-}",
      "+killApplication(appId);",
      "return;",
      "}",
      "",
      "try{",
      "/* send a kill to the AM */",
      "clientCache.getClient(arg0).killJob(arg0);",
      "longcurrentTimeMillis = System.currentTimeMillis();",
      "longtimeKillIssued = currentTimeMillis;",
      "-while((currentTimeMillis < timeKillIssued +10000L) && (status.getState()",
      "-!= JobStatus.State.KILLED)) {",
      "-try{",
      "-Thread.sleep(1000L);",
      "-}catch(InterruptedException ie) {",
      "-/** interrupted, just break */",
      "-break;",
      "-}",
      "-currentTimeMillis = System.currentTimeMillis();",
      "-status =clientCache.getClient(arg0).getJobStatus(arg0);",
      "+while((currentTimeMillis < timeKillIssued + 10000L)",
      "+&& !isJobInTerminalState(status)) {",
      "+try{",
      "+Thread.sleep(1000L);",
      "+} catch (InterruptedException ie) {",
      "+/** interrupted, just break */",
      "+break;",
      "+}",
      "+currentTimeMillis = System.currentTimeMillis();",
      "+status = clientCache.getClient(arg0).getJobStatus(arg0);",
      "+if (status == null) {",
      "+killUnFinishedApplication(appId);",
      "+return;",
      "+}",
      "}",
      "}catch(IOException io) {",
      "LOG.debug(\"Error when checking for application status\", io);",
      "}",
      "-if(status.getState() != JobStatus.State.KILLED) {",
      "-try{",
      "-resMgrDelegate.killApplication(TypeConverter.toYarn(arg0).getAppId());",
      "-}catch(YarnException e) {",
      "-throw newIOException(e);",
      "-}",
      "+if(status != null && !isJobInTerminalState(status)) {",
      "+killApplication(appId);",
      "}",
      "}"
    ]
  },
  "(5) How many nodes are involved in the patch": {
    "p": [
      "YarnRunner",
      "",
      "",
      "",
      ""
    ]
  }
}