{
  "p": [
    "HDFS-3157"
  ],
  "Error in deleting block is keep on coming from DN even after the block report and directory scanning has happened": {},
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "DataNode (client-side)NN(server-side)"
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "Cluster setup: 1NN, Three DN(DN1,DN2,DN3), replication factor-2,",
        "\"dfs.blockreport.intervalMsec\" 300, \"dfs.datanode.directoryscan.interval\" 1",
        "step 1: write one file \"a.txt\" with sync (not closed)(syn guarantees the data has been written into DN)",
        "step 2: Delete the blocks in one of the datanode say DN1(from rbw) to which replication happened.",
        "step 3: close the file.",
        "NameNode:",
        "2012-03-19 13:41:36,905 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_2903555284838653156 to add as corrupt on XX.XX.XX.XX by /XX.XX.XX.XX because reported RBW replica with genstamp 1002 does not match COMPLETE block's genstamp in block map 1003",
        "2012-03-19 13:41:39,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* Removing block blk_2903555284838653156_1003 from neededReplications as it has enough replicas.",
        "DataNode: in which the block is deleted the following exception occured",
        "2012-02-29 13:54:13,126 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Unexpected error trying to delete block blk_2903555284838653156_1003. BlockInfo not found in volumeMap.",
        "2012-02-29 13:54:13,126 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Error processing datanode Command",
        "java.io.IOException: Error in deleting blocks.",
        "at org.apache.hadoop.hdfs.server.datanode.FSDataset.invalidate(FSDataset.java:2061)",
        "at org.apache.hadoop.hdfs.server.datanode.BPOfferService.processCommandFromActive(BPOfferService.java:581)",
        "at org.apache.hadoop.hdfs.server.datanode.BPOfferService.processCommandFromActor(BPOfferService.java:545)",
        "at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.processCommand(BPServiceActor.java:690)",
        "at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:522)",
        "at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:662)",
        "at java.lang.Thread.run(Thread.java:619)"
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "(2.1) When the client writes “a.txt” with sync, NN assigns a GS for this pipeline. Since the replication factor is 2, the data is written into DN1 and DN2.",
      "(2.2) Delete the blocks in one of the datanode say DN1(from RBW) to which replication happened.",
      "Here, the block metadata (e.g. checksum_md5) is still in DN1’s volumeMap, and only the data is removed from the disk.",
      "(2.3) On each DataNode, blockScanner will periodically check whether the block is corrupted by comparing the checksum. Therefore, when deleting the block on DN1, DN1 will mark the block corrupted with old GS (1002), and it will report this corruption(RBW,1002) to NN.",
      "(2.4) NN receives this report. Since the replication factor is 2 the block is replicated to the other DN. At this time, the GS for the pipeline is updated to 1003, and the block state in NN is COMPLETE. However, the information for the corrupted block in DN1’s volumeMap is still (RBW, 1002).",
      "(2.5) NN will ask DN1 to delete the corrupted block with new GS (1003). DN1 processes the command from NN, and tries to invalidate this block. Since DN1 only has the metadata with old GS (1002) for this block in its volumeMap, it throws IOException “Error in deleting blocks”.",
      "(2.6) Then DN1 continues to report the corrupted block to NN with (RBW, 1002). And NN will still ask DN1 to delete the corrupted block with GS 1003.",
      "Therefore, “error in deleting block is keep on coming from DN”."
    ]
  },
  "(3) Root Cause": {
    "p": [
      "When DataNode reports the corrupted block to NN, NN does not differentiate the information/states (“corrupted” and “stored”) for this block, so NN asks DN to corrupt the block by using the “stored” information/state (in this bug, GS 1003). As a result, DN fails to corrupt this block, and continue to report the corrupted block to NN."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "In NN’s block management, it should differentiate the reported block information/state and stored block information/state. And use “corrupted” block information/state to mark the block as corrupted on DN.",
      "Fixing the root cause.",
      "All the fixes are in BlockManager.java, and BlockManager is in NameNode.",
      "•hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "Modify the member variable in class BlockToMarkCorrupt, in order to differentiate “corrupted”(reported by DN) and “stored”(stored in NN) block.",
      "public classBlockManager{* list of blocks that should be considered corrupt due to a block report.*/private static class BlockToMarkCorrupt {- final BlockInfo blockInfo;+ /** The corrupted block in a datanode. */+ final BlockInfo corrupted;+ /** The corresponding block stored in the BlockManager. */+ final BlockInfo stored;+ /** The reason to mark corrupt. */final String reason;- BlockToMarkCorrupt(BlockInfo blockInfo, String reason) {- super();- this.blockInfo = blockInfo;+ BlockToMarkCorrupt(BlockInfo corrupted, BlockInfo stored, String reason) {+ Preconditions.checkNotNull(corrupted, \"corrupted is null\");+ Preconditions.checkNotNull(stored, \"stored is null\");++ this.corrupted = corrupted;+ this.stored = stored;this.reason = reason;}++ BlockToMarkCorrupt(BlockInfo stored, String reason) {+ this(stored, stored, reason);+++ BlockToMarkCorrupt(BlockInfo stored, long gs, String reason) {+ this(new BlockInfo(stored), stored, reason);+ //the corrupted block in datanode has a different generation stamp+ corrupted.setGenerationStamp(gs);+++ @Override+ public String toString() {+ return corrupted + \"(\"+ + (corrupted == stored? \"same as stored\": \"stored=\" + stored) + \")\";+}",
      "Modify function markBlockAsCorrupt(). Change the parameters: replaceBlockInfo storedBlockwithBlockToMarkCorrupt b, and the new type includesString reason.",
      "",
      "private voidmarkBlockAsCorrupt(BlockInfo storedBlock,- DatanodeInfo dn,- String reason) throws IOException {- assert storedBlock != null : \"storedBlock should not be null\";+ private void markBlockAsCorrupt(BlockToMarkCorrupt b,+ DatanodeInfo dn) throws IOException {DatanodeDescriptor node = getDatanodeManager().getDatanode(dn);if (node == null) {- throw new IOException(\"Cannot mark block \" +- storedBlock.getBlockName() +- \" as corrupt because datanode \" + dn +- \" does not exist. \");+ throw new IOException(\"Cannot mark \" + b+ + \" as corrupt because datanode \" + dn + \" does not exist\");}- BlockCollection bc = storedBlock.getBlockCollection();+ BlockCollection bc = b.corrupted.getBlockCollection();if (bc == null) {- NameNode.stateChangeLog.info(\"BLOCK markBlockAsCorrupt: \" +- \"block \" + storedBlock +- \" could not be marked as corrupt as it\" +- \" does not belong to any file\");- addToInvalidates(storedBlock, node);+ NameNode.stateChangeLog.info(\"BLOCK markBlockAsCorrupt: \" + b+ + \" cannot be marked as corrupt as it does not belong to any file\");+addToInvalidates(b.corrupted, node);return;}// Add replica to the data-node if it is not already there- node.addBlock(storedBlock);+ node.addBlock(b.stored);// Add this replica to corruptReplicas Map- corruptReplicas.addToCorruptReplicasMap(storedBlock, node, reason);- if (countNodes(storedBlock).liveReplicas() >= bc.getReplication()) {+corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason);+ if (countNodes(b.stored).liveReplicas() >= bc.getReplication()) {// the block is over-replicated so invalidate the replicas immediately- invalidateBlock(storedBlock, node);+ invalidateBlock(b, node);} else if (namesystem.isPopulatingReplQueues()) {// add the block to neededReplication- updateNeededReplications(storedBlock, -1, 0);+ updateNeededReplications(b.stored, -1, 0);}}",
      "Modify function invalidateBlock(). Change the parameter/*** Invalidates the given block on the given datanode.*/- private void invalidateBlock(Block blk, DatanodeInfo dn)- throws IOException {- NameNode.stateChangeLog.info(\"BLOCK* invalidateBlock: \"- + blk + \" on \" + dn);+ private void invalidateBlock(BlockToMarkCorrupt b, DatanodeInfo dn+ ) throws IOException {+ NameNode.stateChangeLog.info(\"BLOCK* invalidateBlock: \" + b + \" on \" + dn);DatanodeDescriptor node = getDatanodeManager().getDatanode(dn);if (node == null) {- throw new IOException(\"Cannot invalidate block \" + blk+ throw new IOException(\"Cannot invalidate \" + b+ \" because datanode \" + dn + \" does not exist.\");}// Check how many copies we have of the blockWhen counting the replica number of the block, only count the stored block, excluding the corrupted one.- NumberReplicas nr = countNodes(blk);+ NumberReplicas nr = countNodes(b.stored);if (nr.replicasOnStaleNodes() > 0) {NameNode.stateChangeLog.info(\"BLOCK* invalidateBlocks: postponing \" +- \"invalidation of block \" + blk + \" on \" + dn + \" because \" ++ \"invalidation of \" + b + \" on \" + dn + \" because \" +nr.replicasOnStaleNodes() + \" replica(s) are located on nodes \" +\"with potentially out-of-date block reports.\");- postponeBlock(blk);+ postponeBlock(b.corrupted);} else if (nr.liveReplicas() >= 1) {// If we have at least one copy on a live node, then we can delete it.- addToInvalidates(blk, dn);- removeStoredBlock(blk, node);+ addToInvalidates(b.corrupted, dn);+ removeStoredBlock(b.stored, node);if(NameNode.stateChangeLog.isDebugEnabled()) {NameNode.stateChangeLog.debug(\"BLOCK* invalidateBlocks: \"- + blk + \" on \" + dn + \" listed for deletion.\");+ + b + \" on \" + dn + \" listed for deletion.\");}} else {- NameNode.stateChangeLog.info(\"BLOCK* invalidateBlocks: \" + blk + \" on \"- + dn + \" is the only copy and was not deleted.\");+ NameNode.stateChangeLog.info(\"BLOCK* invalidateBlocks: \" + b+ + \" on \" + dn + \" is the only copy and was not deleted.\");}}",
      "",
      "Modify the other functions which call markBlockAsCorrupt().",
      "private voidprocessReport(finalDatanodeDescriptor node,",
      "finalBlockListAsLongs report)throwsIOException { …",
      "for(BlockToMarkCorrupt b : toCorrupt) {",
      "-markBlockAsCorrupt(b.blockInfo, node, b.reason);",
      "+markBlockAsCorrupt(b, node);",
      "}",
      "}",
      "",
      "private voidprocessFirstBlockReport(finalDatanodeDescriptor node,finalBlockListAsLongs report)throwsIOException { …while(itBR.hasNext()) { …if(c !=null) { …}else{",
      "-markBlockAsCorrupt(c.blockInfo, node, c.reason);",
      "+markBlockAsCorrupt(c, node);",
      "}",
      "continue;",
      "}",
      "…",
      "}",
      "}",
      "",
      "public voidfindAndMarkBlockAsCorrupt(final ExtendedBlock blk,",
      "final DatanodeInfo dn, String reason) throws IOException {",
      "assert namesystem.hasWriteLock();",
      "final BlockInfo storedBlock = getStoredBlock(blk.getLocalBlock());",
      "if (storedBlock == null) { … }",
      "-markBlockAsCorrupt(storedBlock, dn, reason);",
      "+markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock, reason), dn);",
      "",
      "}",
      "",
      "",
      "- /*+ /*** The next two methods test the various cases under which we must conclude* the replica is corrupt, or under construction. These are laid out* as switch statements, on the theory that it is easier to understand@@ -1793,7 +1811,7 @@* @return a BlockToMarkCorrupt object, or null if the replica is not corrupt*/private BlockToMarkCorrupt checkReplicaCorrupt(- Block iblk, ReplicaState reportedState,+ Block reported, ReplicaState reportedState,BlockInfo storedBlock, BlockUCState ucState,DatanodeDescriptor dn) {switch(reportedState) {@@ -1801,15 +1819,16 @@switch(ucState) {case COMPLETE:case COMMITTED:Differentiate “repoted” and “stored”- if (storedBlock.getGenerationStamp() != iblk.getGenerationStamp()) {+ if (storedBlock.getGenerationStamp() != reported.getGenerationStamp()) {+ final long reportedGS = reported.getGenerationStamp();+ return new BlockToMarkCorrupt(storedBlock, reportedGS,+ \"block is \" + ucState + \" and reported genstamp \" + reportedGS+ + \" does not match genstamp in block map \"+ + storedBlock.getGenerationStamp());+ } else if (storedBlock.getNumBytes() != reported.getNumBytes()) {return new BlockToMarkCorrupt(storedBlock,- \"block is \" + ucState + \" and reported genstamp \" +- iblk.getGenerationStamp() + \" does not match \" +- \"genstamp in block map \" + storedBlock.getGenerationStamp());- } else if (storedBlock.getNumBytes() != iblk.getNumBytes()) {- return new BlockToMarkCorrupt(storedBlock,\"block is \" + ucState + \" and reported length \" +- iblk.getNumBytes() + \" does not match \" ++ reported.getNumBytes() + \" does not match \" +\"length in block map \" + storedBlock.getNumBytes());} else {return null; // not corrupt@@ -1821,11 +1840,12 @@case RWR:if (!storedBlock.isComplete()) {return null; // not corrupt- } else if (storedBlock.getGenerationStamp() != iblk.getGenerationStamp()) {- return new BlockToMarkCorrupt(storedBlock,- \"reported \" + reportedState + \" replica with genstamp \" +- iblk.getGenerationStamp() + \" does not match COMPLETE block's \" +- \"genstamp in block map \" + storedBlock.getGenerationStamp());+ } else if (storedBlock.getGenerationStamp() != reported.getGenerationStamp()) {+ final long reportedGS = reported.getGenerationStamp();+ return new BlockToMarkCorrupt(storedBlock, reportedGS,+ \"reported \" + reportedState + \" replica with genstamp \" + reportedGS+ + \" does not match COMPLETE block's genstamp in block map \"+ + storedBlock.getGenerationStamp());} else { // COMPLETE block, same genstampif (reportedState == ReplicaState.RBW) {// If it's a RBW report for a COMPLETE block, it may just be that",
      "",
      "",
      "@@ -1847,8 +1867,7 @@String msg = \"Unexpected replica state \" + reportedState+ \" for block: \" + storedBlock +\" on \" + dn + \" size \" + storedBlock.getNumBytes();- // log here at WARN level since this is really a broken HDFS- // invariant+ // log here at WARN level since this is really a broken HDFS invariantLOG.warn(msg);return new BlockToMarkCorrupt(storedBlock, msg);}@@ -2051,7 +2070,7 @@** @param blk Block whose corrupt replicas need to be invalidated*/- private void invalidateCorruptReplicas(Block blk) {+ private void invalidateCorruptReplicas(BlockInfo blk) {Collection<DatanodeDescriptor> nodes = corruptReplicas.getNodes(blk);boolean gotException = false;if (nodes == null)@@ -2061,7 +2080,7 @@DatanodeDescriptor[] nodesCopy = nodes.toArray(new DatanodeDescriptor[0]);for (DatanodeDescriptor node : nodesCopy) {try {- invalidateBlock(blk, node);+ invalidateBlock(new BlockToMarkCorrupt(blk, null), node);} catch (IOException e) {NameNode.stateChangeLog.info(\"NameNode.invalidateCorruptReplicas \" +\"error in deleting bad block \" + blk +@@ -2449,7 +2468,7 @@addToInvalidates(b, node);}for (BlockToMarkCorrupt b : toCorrupt) {- markBlockAsCorrupt(b.blockInfo, node, b.reason);+ markBlockAsCorrupt(b, node);}}"
    ]
  },
  "(5) How many nodes are involved in the patch": {
    "p": [
      "The patch is in NameNode."
    ]
  },
  "(6) Code Snippets": {
    "p": [
      "On DataNode, 0.23.0@Override// FSDatasetInterfacepublic voidinvalidate(String bpid, Block invalidBlks[])throwsIOException {booleanerror =false;for(inti =0; i < invalidBlks.length; i++) {File f =null;FSVolume v;synchronized(this) {f = getFile(bpid, invalidBlks[i]);ReplicaInfo dinfo =volumeMap.get(bpid, invalidBlks[i]);if(dinfo ==null||dinfo.getGenerationStamp() != invalidBlks[i].getGenerationStamp()) {DataNode.LOG.warn(\"Unexpected error trying to delete block \"+ invalidBlks[i] +\". BlockInfo not found in volumeMap.\");error =true;continue;}v = dinfo.getVolume();if(f ==null) { … }if(v ==null) { … }File parent = f.getParentFile();if(parent ==null) { … }ReplicaState replicaState = dinfo.getState();if(replicaState == ReplicaState.FINALIZED||(replicaState == ReplicaState.RUR&&((ReplicaUnderRecovery)dinfo).getOrignalReplicaState() ==ReplicaState.FINALIZED)) {v.clearPath(bpid, parent);}volumeMap.remove(bpid, invalidBlks[i]);}File metaFile =getMetaFile(f, invalidBlks[i].getGenerationStamp());",
      "// Delete the block asynchronously to make sure we can do it fast enough",
      "asyncDiskService.deleteAsync(v, bpid, f, metaFile,invalidBlks[i].toString());}if(error) {throw newIOException(\"Error in deleting blocks.\");}}",
      "NN side: 2.0.0-alpha",
      "private voidprocessReport(finalDatanodeDescriptor node,",
      "finalBlockListAsLongs report)throwsIOException {",
      "// Modify the (block-->datanode) map, according to the difference",
      "// between the old and new block report.",
      "…",
      "reportDiff(node, report, toAdd, toRemove, toInvalidate, toCorrupt, toUC);",
      "",
      "// Process the blocks on each queue",
      "for(StatefulBlockInfo b : toUC) {",
      "addStoredBlockUnderConstruction(b.storedBlock, node, b.reportedState);",
      "}",
      "…",
      "for(BlockToMarkCorrupt b : toCorrupt) {",
      "markBlockAsCorrupt(b.blockInfo, node, b.reason);",
      "}",
      "}",
      "",
      "private voidreportDiff(DatanodeDescriptor dn,",
      "BlockListAsLongs newReport,",
      "Collection<BlockInfo> toAdd,// add to DatanodeDescriptor",
      "Collection<Block> toRemove,// remove from DatanodeDescriptor",
      "Collection<Block> toInvalidate,// should be removed from DN",
      "Collection<BlockToMarkCorrupt> toCorrupt,// add to corrupt replicas list",
      "Collection<StatefulBlockInfo> toUC) {// add to under-construction list",
      "…",
      "while(itBR.hasNext()) {",
      "Block iblk = itBR.next();",
      "ReplicaState iState = itBR.getCurrentReplicaState();",
      "BlockInfo storedBlock =processReportedBlock(dn, iblk, iState, toAdd, toInvalidate, toCorrupt, toUC);",
      "// move block to the head of the list",
      "…",
      "}",
      "// collect blocks that have not been reported",
      "// all of them are next to the delimiter",
      "…",
      "}",
      "",
      "privateBlockInfoprocessReportedBlock() {…",
      "// find block by blockId",
      "BlockInfo storedBlock =blocksMap.getStoredBlock(block);",
      "if(storedBlock ==null) {",
      "// If blocksMap does not contain reported block id,",
      "// the replica should be removed from the data-node.",
      "toInvalidate.add(newBlock(block));",
      "return null;",
      "}",
      "BlockUCState ucState = storedBlock.getBlockUCState();",
      "…",
      "BlockToMarkCorrupt c=checkReplicaCorrupt(",
      "block, reportedState, storedBlock, ucState, dn);",
      "if(c !=null) {",
      "if(namesystem.isInStandbyState()) {",
      "// If the block is an out-of-date generation stamp or state,",
      "// but we're the standby, we shouldn't treat it as corrupt,",
      "// but instead just queue it for later processing.",
      "queueReportedBlock(dn, storedBlock, reportedState,",
      "QUEUE_REASON_CORRUPT_STATE);",
      "}else{ toCorrupt.add(c); }",
      "returnstoredBlock;",
      "}",
      "…",
      "}",
      "",
      "privateBlockToMarkCorruptcheckReplicaCorrupt(Block iblk, ReplicaState reportedState,",
      "BlockInfo storedBlock, BlockUCState ucState, DatanodeDescriptor dn) {",
      "switch(reportedState) {",
      "…",
      "caseRBW:",
      "caseRWR:",
      "if(!storedBlock.isComplete()) {return null;// not corrupt",
      "}else if(storedBlock.getGenerationStamp() != iblk.getGenerationStamp()) {",
      "return newBlockToMarkCorrupt(storedBlock,",
      "\"reported \"+ reportedState +\" replica with genstamp \"+",
      "iblk.getGenerationStamp() +\" does not match COMPLETE block's \"+",
      "\"genstamp in block map \"+ storedBlock.getGenerationStamp());",
      "}else{// COMPLETE block, same genstamp",
      "if(reportedState == ReplicaState.RBW) {",
      "// If it's a RBW report for a COMPLETE block, it may just be that",
      "// the block report got a little bit delayed after the pipeline",
      "// closed. So, ignore this report, assuming we will get a",
      "// FINALIZED replica later. See HDFS-2791",
      "LOG.info(\"Received an RBW replica for block \"+ storedBlock +",
      "\" on \"+ dn +\": ignoring it, since the block is \"+",
      "\"complete with the same generation stamp.\");",
      "return null;",
      "}else{",
      "return newBlockToMarkCorrupt(storedBlock,\"reported replica has invalid state \"+ reportedState);",
      "}",
      "}",
      "…",
      "default:",
      "…",
      "}",
      "}",
      "",
      "After reportDiff(),",
      "private voidmarkBlockAsCorrupt(BlockInfo storedBlock, DatanodeInfo dn,",
      "String reason)throwsIOException {",
      "assertstoredBlock !=null:\"storedBlock should not be null\";",
      "…",
      "// Add replica to the data-node if it is not already there",
      "node.addBlock(storedBlock);",
      "",
      "// Add this replica to corruptReplicas Map",
      "corruptReplicas.addToCorruptReplicasMap(storedBlock, node, reason);",
      "if(countNodes(storedBlock).liveReplicas() >= inode.getReplication()) {",
      "// the block is over-replicated so invalidate the replicas immediately",
      "invalidateBlock(storedBlock, node);",
      "}else if(namesystem.isPopulatingReplQueues()) {",
      "// add the block to neededReplication",
      "updateNeededReplications(storedBlock, -1,0);",
      "}",
      "}",
      "",
      "public voidaddToCorruptReplicasMap(Block blk, DatanodeDescriptor dn,",
      "String reason) {",
      "Collection<DatanodeDescriptor> nodes = getNodes(blk);",
      "if(nodes ==null) {",
      "nodes =newTreeSet<DatanodeDescriptor>();",
      "corruptReplicasMap.put(blk, nodes);",
      "}",
      "",
      "String reasonText;",
      "if(reason !=null) { reasonText =\" because \"+ reason; }",
      "else{ reasonText =\"\"; }",
      "",
      "if(!nodes.contains(dn)) {",
      "nodes.add(dn);",
      "NameNode.stateChangeLog.info(\"BLOCK NameSystem.addToCorruptReplicasMap: \"+",
      "blk.getBlockName() +\" added as corrupt on \"+ dn +\" by \"+ Server.getRemoteIp() +",
      "reasonText);",
      "}else{",
      "NameNode.stateChangeLog.info(\"BLOCK NameSystem.addToCorruptReplicasMap: \"+",
      "\"duplicate requested for \"+ blk.getBlockName() +\" to add as corrupt \"+",
      "\"on \"+ dn +\" by \"+ Server.getRemoteIp() + reasonText);",
      "}",
      "}",
      ""
    ]
  }
}