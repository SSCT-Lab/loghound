{
  "p": [
    "HBase-4792"
  ],
  "SplitRegionHandler doesn't care if it deletes the znode or not, leaves the parent region stuck offline": {},
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "RegionServer is waiting for HMaster to delete the ZNode"
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "HMaster log:",
        "2011-11-15 22:28:57,900 DEBUG org.apache.hadoop.hbase.master.handler.SplitRegionHandler:Handling SPLIT eventfore5be6551c8584a6a1065466e520faf4e; deleting node",
        "2011-11-15 22:28:57,900 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:62003-0x132f043bbde08c1 Deleting existing unassigned node fore5be6551c8584a6a1065466e520faf4ethat is in expected state RS_ZK_REGION_SPLIT",
        "2011-11-15 22:28:57,975 WARN org.apache.hadoop.hbase.zookeeper.ZKAssign: master:62003-0x132f043bbde08c1Attempting to delete unassigned nodein RS_ZK_REGION_SPLIT statebut after verifying state, we got a version mismatchWhen this WARN is printed, ZKUtil.deleteNode() fails and returnsFALSE.",
        "2011-11-15 22:28:57,975 INFO org.apache.hadoop.hbase.master.handler.SplitRegionHandler: Handled SPLIT report); parent=TestTable,0001355346,1321396080924.e5be6551c8584a6a1065466e520faf4e. daughter a=TestTable,0001355346,1321396132414.df9b549eb594a1f8728608a2a431224a.daughter b=TestTable,0001368082,1321396132414.de861596db4337dc341138f26b9c8bc2.",
        "",
        "“The master processes the split but when it calls ZKAssign.deleteNode it doesn't check the boolean that's returned. In this case it was false. So for the master the split was completed, but for the region server it's another story:”",
        "(RS log)",
        "2011-11-15 22:28:57,661 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:62023-0x132f043bbde08d3 Attempting to transition nodee5be6551c8584a6a1065466e520faf4efromRS_ZK_REGION_SPLITTINGtoRS_ZK_REGION_SPLIT",
        "2011-11-15 22:28:57,775 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:62023-0x132f043bbde08d3 Successfully transitioned nodee5be6551c8584a6a1065466e520faf4efrom RS_ZK_REGION_SPLITTING to RS_ZK_REGION_SPLIT",
        "2011-11-15 22:28:57,775 INFO org.apache.hadoop.hbase.regionserver.SplitTransaction:Still waiting on the master to process the splitfore5be6551c8584a6a1065466e520faf4e",
        "2011-11-15 22:28:57,876 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:62023-0x132f043bbde08d3Attemptingto transition nodee5be6551c8584a6a1065466e520faf4efrom RS_ZK_REGION_SPLITto RS_ZK_REGION_SPLIT",
        "2011-11-15 22:28:57,967 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:62023-0x132f043bbde08d3Successfullytransitioned nodee5be6551c8584a6a1065466e520faf4efrom RS_ZK_REGION_SPLITto RS_ZK_REGION_SPLIT",
        ""
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "(2.1) When RS finishes region split, it will make znode transition from RS_ZK_REGION_SPLITTING to RS_ZK_REGION_SPLIT on ZK. Then HMaster’s ZooKeeperWatch will detect this znode data change, and callhandleRegion(), which then callsSplitRegionHandler.process() to process the SPLIT event.",
      "Before deleting the ZNode,handleSplitReport() is called to update the parent and daughters state, which will remove the parent region’s RIT and HRegionInfo.",
      "",
      "public voidprocess() {",
      "String encodedRegionName =this.parent.getEncodedName();",
      "LOG.debug(\"Handling SPLIT event for \"+ encodedRegionName",
      "+\"; deleting node\");",
      "...",
      "this.assignmentManager.handleSplitReport(this.sn,this.parent,",
      "this.daughters.get(0),this.daughters.get(1));",
      "// Remove region from ZK",
      "try{",
      "ZKAssign.deleteNode(this.server.getZooKeeper(),this.parent.getEncodedName(),",
      "EventHandler.EventType.RS_ZK_REGION_SPLIT);the return value of deleteNode() is not checked, so HMaster will not know if it fails to delete the ZNode.}catch(KeeperException e) {server.abort(\"Error deleting SPLIT node in ZK for transition ZK node (\"+parent.getEncodedName() +\")\", e);}",
      "LOG.info(\"Handled SPLIT event; parent=\"+this.parent.getRegionNameAsString() +\" daughter a=\"+this.daughters.get(0).getRegionNameAsString() +\"daughter b=\"+this.daughters.get(1).getRegionNameAsString());}",
      "",
      "(2.2) After making znode transition from SPLITTING to SPLIT by callingtransitionNodeSplit(), RS will waits for the master to process the split. We know it is done when the znode is deleted.tickeNodeSplit()is called with the loop to check whether the znode is deleted.",
      "",
      "voidtransitionZKNode(finalServer server, HRegion a, HRegion b)throwsIOException {",
      "// Tell master about split by updating zk. If we fail, abort.",
      "if(server !=null&& server.getZooKeeper() !=null) {",
      "try{",
      "this.znodeVersion=transitionNodeSplit(server.getZooKeeper(),(RS_ZK_REGION_SPLITTING →RS_ZK_REGION_SPLIT)",
      "parent.getRegionInfo(), a.getRegionInfo(), b.getRegionInfo(),",
      "server.getServerName(),this.znodeVersion);",
      "",
      "intspins =0;",
      "do{if(spins %10==0) {",
      "LOG.debug(\"Still waiting on the master to process the split for \"+",
      "this.parent.getRegionInfo().getEncodedName());",
      "}",
      "Thread.sleep(100);",
      "// When this returns -1 it means the znode doesn't exist",
      "this.znodeVersion=tickleNodeSplit(server.getZooKeeper(),(RS_ZK_REGION_SPLIT→ RS_ZK_REGION_SPLIT)",
      "parent.getRegionInfo(), a.getRegionInfo(), b.getRegionInfo(),",
      "server.getServerName(),this.znodeVersion);",
      "spins++;",
      "}while(this.znodeVersion!= -1);",
      "}catch(Exception e) {",
      "if(einstanceofInterruptedException) { Thread.currentThread().interrupt(); }",
      "throw newIOException(\"Failed telling master about split\", e);",
      "}",
      "}",
      "...",
      "}",
      "IntickeNodeSplit(), it tries to transit the znode form SPLIT to SPLIT, since the znode still exists (HMaster fails to delete it), the transition from SPLIT to SPLIT will be successful.",
      "",
      "(2.3) Correspondingly, HMaster’s ZooKeeperWatch will detect this znode data change, and call handleRegion() again.",
      "",
      "private voidhandleRegion(finalRegionTransitionData data,intexpectedVersion) {",
      "synchronized(regionsInTransition) {...",
      "String encodedName = HRegionInfo.encodeRegionName(data.getRegionName());String prettyPrintedRegionName = HRegionInfo.prettyPrint(encodedName);// Verify this is a known server...LOG.debug(\"Handling transition=\"+ data.getEventType() +\", server=\"+ data.getOrigin() +\",",
      "region=\"+ (prettyPrintedRegionName ==null?\"null\": prettyPrintedRegionName) +",
      "(lateEvent?\", which is more than 15 seconds late\":\"\"));",
      "RegionStateregionState=regionsInTransition.get(encodedName);",
      "switch(data.getEventType()) {caseM_ZK_REGION_OFFLINE:// Nothing to do.break;",
      "caseRS_ZK_REGION_SPLITTING:if(!isInStateForSplitting(regionState))break;addSplittingToRIT(sn, encodedName);break;",
      "caseRS_ZK_REGION_SPLIT:// RegionState must be null, or SPLITTING or PENDING_CLOSE.if(!isInStateForSplitting(regionState))break;// If null, add SPLITTING state before going to SPLITif(regionState ==null) {The parent region is already removed from RIT, so regionState ==null.regionState =addSplittingToRIT(sn, encodedName);Since the regionInfo is deleted, addSplittingToRIT() returns null.String message =\"Received SPLIT for region \"+ prettyPrintedRegionName +\" from server \"+ sn;// If still null, it means we cannot find it and it was already processedif(regionState ==null) {LOG.warn(message +\" but it doesn't exist anymore,\"+\" probably already processed its split\");break;}",
      "LOG.info(message +\" but region was not first in SPLITTING state; continuing\");}",
      "// Check it has daughters....assertdaughters.size() ==2;// Assert that we can get a serverinfo for this server....// Run handler to do the rest of the SPLIT handling.this.executorService.submit(newSplitRegionHandler(master,this,regionState.getRegion(), sn, daughters));break;",
      "caseM_ZK_REGION_CLOSING:...break;caseRS_ZK_REGION_CLOSED:...break;caseRS_ZK_REGION_FAILED_OPEN:...break;",
      "caseRS_ZK_REGION_OPENING:...break;caseRS_ZK_REGION_OPENED:...break;}}}",
      "At this time, SplitRegionHandler will not be executed, so there is no chance to delete the znode for the parent region.",
      "As a result, RS cannot exit the do-while loop (keep tickleNodeSplit()), and HMaster continuously calls handleRegion(). The repeated logs print on both HMaster and RS."
    ]
  },
  "(3) Root Cause": {
    "p": [
      "When RS finishes splitting, it is waiting HMaster to delete the znode. However, when SplitRegionHandler is called to delete the znode, it does not check whether the znode is deleted successfully or not.",
      "The failure of deleting znode makes RS keep tickeNodeSplit(), which triggers the handleRegion() on HMaster continuously and generates lots of repeated logs on both side."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "Fixing the effect brought by failing to delete the znode.",
      "Check the return value of ZKAssign.deleteNode(). If it is false, just retry.",
      "• src/main/java/org/apache/hadoop/hbase/master/handler/SplitRegionHandler.java",
      "public voidprocess() {",
      "String encodedRegionName =this.parent.getEncodedName();",
      "LOG.debug(\"Handling SPLIT event for \"+ encodedRegionName +",
      "\"; deleting node\");",
      "// The below is for testing ONLY! We can't do fault injection easily, so",
      "// resort to this kinda uglyness -- St.Ack 02/25/2011.",
      "if(TEST_SKIP) {",
      "LOG.warn(\"Skipping split message, TEST_SKIP is set\");",
      "return;",
      "}",
      "this.assignmentManager.handleSplitReport(this.sn,this.parent,",
      "this.daughters.get(0),this.daughters.get(1));",
      "// Remove region from ZK",
      "try{",
      "-ZKAssign.deleteNode(this.server.getZooKeeper(),",
      "-this.parent.getEncodedName(),",
      "-EventHandler.EventType.RS_ZK_REGION_SPLIT);",
      "+",
      "+booleansuccessful =false;",
      "+while(!successful) {",
      "+// It's possible that the RS tickles in between the reading of the",
      "+// znode and the deleting, so it's safe to retry.",
      "+successful = ZKAssign.deleteNode(this.server.getZooKeeper(),",
      "+encodedRegionName,",
      "+EventHandler.EventType.RS_ZK_REGION_SPLIT);",
      "+}",
      "}catch(KeeperException e) {",
      "if(einstanceofNoNodeException) {",
      "String znodePath = ZKUtil.joinZNode(this.server.getZooKeeper().splitLogZNode, encodedRegionName);",
      "LOG.debug(\"The znode \"+ znodePath",
      "+\" does not exist. May be deleted already.\");",
      "}else{server.abort(\"Error deleting SPLIT node in ZK for transition ZK node (\"+",
      "parent.getEncodedName() +\")\", e);",
      "}",
      "}",
      "LOG.info(\"Handled SPLIT event; parent=\"+",
      "this.parent.getRegionNameAsString() +",
      "\" daughter a=\"+this.daughters.get(0).getRegionNameAsString() +",
      "\"daughter b=\"+this.daughters.get(1).getRegionNameAsString());",
      "}",
      "",
      "It is better to print out the name of the region in the message, which will facilitate the developer to debug.",
      "• src/main/java/org/apache/hadoop/hbase/zookeeper/ZKAssign.java",
      "public static booleandeleteNode(ZooKeeperWatcher zkw, String regionName,EventType expectedState,intexpectedVersion)throwsKeeperException, KeeperException.NoNodeException {LOG.debug(zkw.prefix(\"Deleting existing unassigned \"+\"node for \"+ regionName +\" that is in expected state \"+ expectedState));String node =getNodeName(zkw, regionName);zkw.sync(node);Stat stat =newStat();byte[] bytes = ZKUtil.getDataNoWatch(zkw, node, stat);...if(expectedVersion != -1&& stat.getVersion() != expectedVersion) {",
      "-LOG.warn(\"The node we are trying to delete is not the expected one. \"+",
      "-\" Got a version mismatch\");+LOG.warn(\"The node \"+ regionName +\" we are trying to delete is not\"++\" the expected one. Got a version mismatch\");",
      "LOG.warn(\"The node we are trying to delete is not the expected one. \"+",
      "\" Got a version mismatch\");return false;}if(!ZKUtil.deleteNode(zkw, node, stat.getVersion())) {LOG.warn(zkw.prefix(\"Attempting to delete \"+",
      "-\"unassigned node in \"+ expectedState ++\"unassigned node \"+ regionName +\" in \"+ expectedState +\" state but after verifying state, we got a version mismatch\"));return false;}",
      "LOG.debug(zkw.prefix(\"Successfully deleted unassigned node for region \"+regionName +\" in expected state \"+ expectedState));return true;}"
    ]
  },
  "(5) How many nodes are involved in the patch": {
    "p": [
      "HMaster"
    ]
  },
  "(6) Code Snippets": {
    "p": [
      "public static booleandeleteNode(ZooKeeperWatcher zkw, String regionName,EventType expectedState)throwsKeeperException, KeeperException.NoNodeException {returndeleteNode(zkw, regionName, expectedState, -1);}",
      "",
      "public static booleandeleteNode(ZooKeeperWatcher zkw, String regionName,EventType expectedState,intexpectedVersion)throwsKeeperException, KeeperException.NoNodeException {LOG.debug(zkw.prefix(\"Deleting existing unassigned \"+\"node for \"+ regionName +\" that is in expected state \"+ expectedState));String node =getNodeName(zkw, regionName);zkw.sync(node);Stat stat =newStat();byte[] bytes = ZKUtil.getDataNoWatch(zkw, node, stat);...if(expectedVersion != -1&& stat.getVersion() != expectedVersion) {",
      "LOG.warn(\"The node we are trying to delete is not the expected one. \"+\" Got a version mismatch\");return false;}",
      "if(!ZKUtil.deleteNode(zkw, node, stat.getVersion())) {LOG.warn(zkw.prefix(\"Attempting to delete \"+",
      "\"unassigned node in \"+ expectedState +\" state but after verifying state, we got a version mismatch\"));return false;}",
      "LOG.debug(zkw.prefix(\"Successfully deleted unassigned node for region \"+regionName +\" in expected state \"+ expectedState));return true;}",
      "",
      "public voidregionOffline(finalHRegionInfo regionInfo) {synchronized(this.regionsInTransition) {if(this.regionsInTransition.remove(regionInfo.getEncodedName()) !=null) {this.regionsInTransition.notifyAll();}}// remove the region plan as well just in case.clearRegionPlan(regionInfo);setOffline(regionInfo);}",
      "public voidsetOffline(HRegionInfo regionInfo) {synchronized(this.regions) {ServerName sn =this.regions.remove(regionInfo);if(sn ==null)return;Set<HRegionInfo> serverRegions =this.servers.get(sn);if(!serverRegions.remove(regionInfo)) {LOG.warn(\"No \"+ regionInfo +\" on \"+ sn); }}}",
      "",
      "privateRegionStateaddSplittingToRIT(finalServerName serverName,finalString encodedName) {RegionState regionState =null;synchronized(this.regions) {regionState =findHRegionInfoThenAddToRIT(serverName, encodedName);if(regionState !=null) { regionState.update(RegionState.State.SPLITTING,System.currentTimeMillis(), serverName);}}returnregionState;}",
      "privateRegionStatefindHRegionInfoThenAddToRIT(finalServerName serverName,finalString encodedName) {HRegionInfo hri =findHRegionInfo(serverName, encodedName);if(hri ==null) {LOG.warn(\"Region \"+ encodedName +\" not found on server \"+ serverName +\"; failed processing\");returnnull;}// Add to regions in transition, then update state to SPLITTING.returnaddToRegionsInTransition(hri);}",
      "",
      "private static inttickleNodeSplit(ZooKeeperWatcher zkw,HRegionInfo parent, HRegionInfo a, HRegionInfo b, ServerName serverName,final intznodeVersion)throwsKeeperException, IOException {byte[] payload = Writables.getBytes(a, b);returnZKAssign.transitionNode(zkw, parent, serverName,EventType.RS_ZK_REGION_SPLIT, EventType.RS_ZK_REGION_SPLIT, znodeVersion, payload);}",
      "",
      ""
    ]
  }
}