{
  "p": [
    "MAPREDUCE-3226",
    "Few reduce tasks hanging in a gridmix-run"
  ],
  "(1) Log information": {
    "p": [
      "Description: “In a gridmix run with ~1000 jobs, one job is getting stuck because of 2-3 hanging reducers. All of them are stuck after downloading all map outputs and have the following thread dump.”"
    ],
    "(1.1) Roles in this case": {
      "p": [
        "Reduce task: client-side AM:server-side"
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "(Reduce Task logs)",
        "2011-10-18 10:34:41,006 INFO org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Failed on local exception:java.nio.channels.ClosedByInterruptException; Host Details : local host is:\"host.name.com/$IP\"; destination host is:“\"host.name.com\":48314;",
        "at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:601)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1089)",
        "at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)",
        "at $Proxy6.statusUpdate(Unknown Source)",
        "at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:671)",
        "at java.lang.Thread.run(Thread.java:619)",
        "Caused by:java.nio.channels.ClosedByInterruptException",
        "atjava.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)",
        "at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)",
        "at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:60)",
        "at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)",
        "at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:151)",
        "atorg.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:112)",
        "at org.apache.hadoop.security.SaslOutputStream.write(SaslOutputStream.java:168)",
        "at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)",
        "at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)",
        "at java.io.DataOutputStream.flush(DataOutputStream.java:106)",
        "at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:796)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1066)",
        "at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)",
        "at $Proxy6.getMapCompletionEvents(Unknown Source)",
        "at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents(EventFetcher.java:99)",
        "atorg.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:65)",
        "Thehanging reducers’ thread dump:",
        "\"EventFetcher for fetching Map Completion Events\"daemon prio=10 tid=0xa325fc00 nid=0x1ca4 waiting on condition [0xa315c000]",
        "java.lang.Thread.State:TIMED_WAITING (sleeping)",
        "at java.lang.Thread.sleep(Native Method)",
        "at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:71)",
        "\"main\"prio=10 tid=0x080ed400 nid=0x1c71 in Object.wait() [0xf73a2000]",
        "java.lang.Thread.State: WAITING (on object monitor)",
        "at java.lang.Object.wait(Native Method)",
        "-waiting on<0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)",
        "at java.lang.Thread.join(Thread.java:1143)",
        "-locked<0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)",
        "at java.lang.Thread.join(Thread.java:1196)",
        "at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:135)",
        "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:367)",
        "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)",
        "at java.security.AccessController.doPrivileged(Native Method)",
        "at javax.security.auth.Subject.doAs(Subject.java:396)",
        "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)",
        "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)"
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "",
      "In shuffle.run(), the eventFetcher is for fetching map completion events, and its result is used by fetcher threads in shuffle.run() to copy map output. The while loop in shuffle.run() is waiting for shuffle to complete successfully, i.e., finishing copying all the map output. After that, it will call evenFetcher.interrupt() to stop the event-fetcher thread. The code for eventFetcher.run() is:",
      "public voidrun() {",
      "intfailures = 0;",
      "LOG.info(reduce+\" Thread started: \"+ getName());",
      "try{",
      "-while (true) {",
      "+while(true && !Thread.currentThread().isInterrupted()) {",
      "try{",
      "",
      "intnumNewMaps =getMapCompletionEvents();(throw IOException)",
      "failures = 0;",
      "if(numNewMaps > 0) {LOG.info(reduce+\": \"+\"Got\"+ numNewMaps +\"new map-outputs\"); }",
      "LOG.debug(\"GetMapEventsThread about to sleep for\"+SLEEP_TIME);",
      "-Thread.sleep(SLEEP_TIME);",
      "+if(!Thread.currentThread().isInterrupted()) {",
      "+Thread.sleep(SLEEP_TIME);",
      "+}",
      "}catch(IOException ie) {LOG.info(\"Exception in getting events\", ie);",
      "// check to see whether to abort",
      "if(++failures >=MAX_RETRIES) {throw newIOException(\"too many failures downloading events\", ie); }",
      "// sleep for a bit",
      "-Thread.sleep(RETRY_PERIOD);",
      "+if(!Thread.currentThread().isInterrupted()) {",
      "+Thread.sleep(RETRY_PERIOD);",
      "+}",
      "}//catch",
      "}//while",
      "}catch(InterruptedException e) {return;",
      "}catch(Throwable t) {exceptionReporter.reportException(t);return; }",
      "}",
      "· In the normal case, when the eventFetcher thread is blocked in sleep(), once eventFetcher.interrupt() is called, its interrupt status will be cleared and it will receive an InterruptedException, which will make it “return”, so the eventFetcher thread is stopped successfully. And in shuffle.run(), the following operations will be executed.",
      "· When the eventFetcher thread is calling getMapCompletionEvents(), and it is blocked in an I/O operation upon an java.nio.channel, the eventFetcher.interrupt() will result in java.nio.channels.ClosedByInterruptException. Then getMapCompletionEvents() will throw IOException and caught by the inner catch block. Since the current condition for while loop is “true”, eventFetcher will not exit this loop, and the eventFetcher thread can’t stop. So the eventFetcher.join() in shuffle.run() will be waiting, which makes the reducer hang. The hanging reducer’s thread dump also indicates this:",
      "\"main\"prio=10 tid=0x080ed400 nid=0x1c71 in Object.wait() [0xf73a2000]",
      "java.lang.Thread.State: WAITING (on object monitor)",
      "at java.lang.Object.wait(Native Method)",
      "-waiting on<0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)",
      "at java.lang.Thread.join(Thread.java:1143)",
      "-locked<0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)",
      "at java.lang.Thread.join(Thread.java:1196)",
      "· Unless that when failures >= MAX_RETRIES(default is 3), eventFetcher thread will throw new IOException and exit the while loop.",
      "· With the fix in the while condition: true && !Thread.currentThread().isInterrupted(), eventFetcher can exit and avoid the hang.",
      "Based on the source code, we can get the control flow showed at the beginning.",
      "Based on the “caused by” informaiton of the logs provided in the bug report, we can get where the root exception”ClosedByInterruptException” happened.",
      "Caused by:java.nio.channels.ClosedByInterruptException",
      "atjava.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)",
      "at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)",
      "at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:60)",
      "at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)",
      "at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:151)",
      "atorg.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:112)",
      "at org.apache.hadoop.security.SaslOutputStream.write(SaslOutputStream.java:168)",
      "at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)",
      "at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)",
      "at java.io.DataOutputStream.flush(DataOutputStream.java:106)",
      "at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:796)",
      "at org.apache.hadoop.ipc.Client.call(Client.java:1066)",
      "at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)",
      "at $Proxy6.getMapCompletionEvents(Unknown Source)",
      "at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents(EventFetcher.java:99)",
      "atorg.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:65)",
      "",
      "The above call-stack shows that getMapCompletionEvents() is invoked through RPC call.",
      "The invoked method layer by layer is marked inblue.",
      "",
      "private intgetMapCompletionEvents()throwsIOException {",
      "intnumNewMaps = 0;",
      "MapTaskCompletionEventsUpdate update =",
      "umbilical.getMapCompletionEvents(...);(throw IOException)",
      "…",
      "}",
      "",
      "publicObjectinvoke(Object proxy, Method method, Object[] args)",
      "throwsThrowable {",
      "ObjectWritable value = (ObjectWritable)client.call(newInvocation(method, args),remoteId);(throw IOException)",
      "…",
      "returnvalue.get();",
      "}",
      "",
      "➡publicWritablecall(Writable param, ConnectionId remoteId)throwsInterruptedException, IOException",
      "{",
      "Call call =newCall(param);",
      "Connection connection = getConnection(remoteId, call);",
      "connection.sendParam(call); // send the parameter",
      "booleaninterrupted =false;",
      "synchronized(call) {",
      "while(!call.done) {(notifyAll() in markClosed() will interrupt call.wait(). So",
      "try{InterruptedException happened and the interrupted status",
      "call.wait();of the current thread is cleared when this exception is thrown.)",
      "}catch(InterruptedExceptionie) { // save the fact that we were interrupted",
      "interrupted =true;",
      "}",
      "}",
      "if(interrupted) { // set the interrupt flag now that we are done waiting",
      "Thread.currentThread().interrupt();(set the interrupted status of the current thread)",
      "}",
      "if(call.error!=null) {",
      "if(call.errorinstanceofRemoteException) { call.error.fillInStackTrace();throwcall.error; }",
      "else{// local exception",
      "InetSocketAddress address = remoteId.getAddress();",
      "throwNetUtils.wrapException(address.getHostName(), address.getPort(),",
      "NetUtils.getHostname(),0,call.error); }",
      "}else{returncall.value; }",
      "}//synchronized",
      "}",
      "",
      "➡public voidsendParam(Call call) { …",
      "try{",
      "synchronized (this.out) {",
      "…",
      "out.flush();(The channel is closed, so ClosedByInterruptException is thrown.)",
      "}",
      "}catch(IOExceptione) {",
      "markClosed(e);",
      "}finally{ IOUtils.closeStream(d); //the buffer is just an in-memory buffer, but it is still polite to close early",
      "}",
      "}",
      "",
      "private synchronized voidmarkClosed(IOException e) {",
      "if(shouldCloseConnection.compareAndSet(false,true)) {",
      "closeException= e;",
      "notifyAll();",
      "}",
      "}",
      "",
      "When executing out.flush() in sendParam(), the channel was closed due to the eventFetcher.interrupt() in shuffle.run(), and it threw ClosedByInterruptException and Caught by “catch(IOException e)” block. Then markClosed(e) is invoked, the root exception wil be saved in the variable closeException, and contained in call.error. The method notifyAll() will interrupt call.wait(), and InterruptedException will be thrown. Since call.error is an local exception, it will wrapped byNetUtils.wrapExceptionand then thown as an IOException. So ipc.Client.call() will throw an IOException. Finally, getMapCompletionEvents() in eventFetcher.run() will throw an IOException.",
      "",
      "publicstaticIOExceptionwrapException() {",
      "if(exceptioninstanceofBindException) {",
      "return newBindException(…);",
      "}else if(exceptioninstanceofConnectException) {// connection refused",
      "return(ConnectException)newConnectException(…);",
      "}else if(exceptioninstanceofUnknownHostException) {",
      "return(UnknownHostException)newUnknownHostException(…);",
      "}else if(exceptioninstanceofSocketTimeoutException) {",
      "return(SocketTimeoutException)newSocketTimeoutException(…);",
      "}else if(exceptioninstanceofNoRouteToHostException) {",
      "return(NoRouteToHostException)newNoRouteToHostException(…);",
      "}else{return(IOException)newIOException(\"Failed on local exception: “+ exception",
      "+\"; Host Details : \"+getHostDetailsAsString(...)).initCause(exception);",
      "}",
      "}"
    ]
  },
  "(3) Root Cause": {
    "p": [
      "eventFetcher.interrupt() is invoked when the eventFetcher thread is blocked in an I/O operation upon an channel. So eventFetcher thread cannot be stopped by the expected InterruptedException, which make the reduce task hang."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "I think the patch belongs to “fixing the root cause”, since it fixes the eventFetcher to stop properly.",
      "The main fix of the patch is in EventFetcher.run(), which modifies the condition for while loop. This has been explained in part (2).",
      "A similar fix has also been applied to Fetcher.run:",
      "Fixing Fetcher thread just in case. Fetcher thread is started after eventFetcher thread’s start.(see the control flow figure)",
      "public void run() {",
      "try {",
      "- while (true) {",
      "+ while (true && !Thread.currentThread().isInterrupted()) {",
      "MapHost host = null;",
      "try {",
      "// If merge is on, block",
      "Since there is no Thread.sleep in Fetcher.run,so only the while loop condition is modified."
    ]
  },
  "(5) How many nodes are involved in the patch? (multiple/single node(s))": {
    "p": [
      "Since eventFetcher thread in reduce task, so the patch will act on each reduce task.",
      ""
    ]
  }
}