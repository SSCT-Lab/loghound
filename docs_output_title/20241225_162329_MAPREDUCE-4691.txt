{
  "p": [
    "MAPREDUCE-4691",
    "Historyserver can report \"Unknown job\" after RM says job has completed"
  ],
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "JobClient (client-side) Job HistoryServer (server-side)"
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "Example traceback from the client:",
        "2012-09-27 20:28:38,068 [main] INFO org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server",
        "2012-09-27 20:28:38,530 [main] WARN org.apache.hadoop.mapred.ClientServiceDelegate - Error from remote end: Unknown job job_1348097917603_3019",
        "2012-09-27 20:28:38,530 [main] ERROR org.apache.hadoop.security.UserGroupInformation - PriviledgedActionException as:xxx (auth:KERBEROS) cause:org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1348097917603_3019",
        "2012-09-27 20:28:38,531 [main] WARN org.apache.pig.tools.pigstats.JobStats - Failed to get map task report",
        "RemoteTrace:",
        "at LocalTrace:",
        "org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1348097917603_3019",
        "at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:156)",
        "at $Proxy11.getJobReport(Unknown Source)",
        "at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getJobReport(MRClientProtocolPBClientImpl.java:116)",
        "at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)",
        "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
        "at java.lang.reflect.Method.invoke(Method.java:597)",
        "at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:298)",
        "at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:383)",
        "at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:482)",
        "at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:184)",
        "..."
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "When the job is running, its log files will be written into the intermediate file directory(hdfs://yarn.app.mapreduce.am.staging-dir/history/done_intermediate/$user), the job is run by $user. When the job finished, these log files will be moved to DONE file directory (hdfs://yarn.app.mapreduce.am.staging-dir/history/done). These files will not be moved right away, the thread may take some time to execute “moveToDone” periodically.",
      "",
      "In this bug, when the client query the job status, since the job is finished, the client will redirect to Job history server(HS) to get the status.",
      "According to the callstack in the log, we can get the following call relationship of the client side.",
      "JobStatus status = client.getJobStatus(jobId);Cluster.java:184",
      "",
      "JobStatus status = clientCache.getClient(jobID).getJobStatus(jobID);YARNRunner.java:482",
      "",
      "public JobStatusgetJobStatus(JobID oldJobID) throws IOException {",
      "….",
      "JobReport report = ((GetJobReportResponse)invoke(\"getJobReport\",GetJobReportRequest.class, request)).getJobReport();The method“getJobReport”is invoked through java dynamic proxyClientServiceDelegate.java:383",
      "…",
      "}",
      "private synchronizedObjectinvoke(String method, Class argClass,Object args)throwsIOException {…",
      "while(maxRetries >0) { //The number of client retries to the RM/HS/AM before throwing exception.",
      "try{",
      "returnmethodOb.invoke(getProxy(), args);ClientServiceDelegate.java:298",
      "}catch(YarnRemoteException yre) {",
      "LOG.warn(\"Exception thrown by remote end.\", yre);",
      "throwyre;",
      "}catch(InvocationTargetExceptione) {",
      "if(e.getTargetException()instanceofYarnRemoteException) {",
      "LOG.warn(\"Error fromremoteend: \"+ e.getTargetException().getLocalizedMessage());",
      "LOG.debug(\"Tracing remote error \", e.getTargetException());",
      "throw(YarnRemoteException) e.getTargetException();",
      "} …",
      "}catch(Exception e) { … }",
      "}// while",
      "throwlastException;",
      "}",
      "",
      "publicObjectinvoke(Object obj, Object... args)",
      "throwsIllegalAccessException, IllegalArgumentException,InvocationTargetException",
      "{ …",
      "returnma.invoke(obj, args);Method.java:597",
      "}",
      "",
      "classDelegatingMethodAccessorImplextendsMethodAccessorImpl {",
      "publicObjectinvoke(Object var1, Object[] var2)throwsIllegalArgumentException,InvocationTargetException{",
      "return this.delegate.invoke(var1, var2);DelegatingMethodAccessorImpl.java:25",
      "}",
      "}",
      "",
      "publicGetJobReportResponsegetJobReport(GetJobReportRequest request)throwsYarnRemoteException {",
      "GetJobReportRequestProto requestProto = ((GetJobReportRequestPBImpl)request).getProto();",
      "try{MRClientProtocolPBClientImpl.java:116",
      "return newGetJobReportResponsePBImpl(proxy.getJobReport(null, requestProto));",
      "}catch(ServiceException e) {",
      "if(e.getCause()instanceofYarnRemoteException) {",
      "throw(YarnRemoteException)e.getCause();",
      "}else if(e.getCause()instanceofUndeclaredThrowableException) {",
      "throw(UndeclaredThrowableException)e.getCause();",
      "}else{throw newUndeclaredThrowableException(e);",
      "}",
      "}",
      "}",
      "",
      "publicObjectinvoke(Object proxy, Method method, Object[] args)throwsThrowable {",
      "…",
      "ProtoSpecificRpcRequestrpcRequest= constructRpcRequest(method, args);",
      "ProtoSpecificResponseWritable val =null;",
      "try{",
      "val = (ProtoSpecificResponseWritable)client.call(",
      "newProtoSpecificRequestWritable(rpcRequest), remoteId);",
      "}catch(Exception e) {throw newServiceException(e); }",
      "ProtoSpecificRpcResponseresponse= val.message;",
      "…",
      "if(response.hasIsError() && response.getIsError() ==true) {",
      "YarnRemoteExceptionPBImpl exception =newYarnRemoteExceptionPBImpl(response.getException());",
      "exception.fillInStackTrace();ProtoOverHadoopRpcEngine.java:156",
      "ServiceException se =newServiceException(exception);",
      "throwse;",
      "}",
      "…",
      "}",
      "public voidprintStackTrace(PrintWriter pw) {YarnRemoteException.java:156",
      "pw.append(\"RemoteTrace:\\n\").append(getRemoteTrace())",
      ".append(\" at LocalTrace:\\n\\t\");",
      "super.printStackTrace(pw);",
      "}",
      "",
      "",
      "",
      "",
      "",
      "",
      "MRClientProtocolPBClientImplimplementsMRClientProtocol",
      "",
      "In the History Server side, we can get the following call relationship based on the source code.",
      "publicGetJobReportResponsegetJobReport(GetJobReportRequest request) throws YarnRemoteException {",
      "JobId jobId = request.getJobId();",
      "Job job =verifyAndGetJob(jobId);HistoryClientService.java",
      "GetJobReportResponse response = recordFactory.newRecordInstance(GetJobReportResponse.class);",
      "response.setJobReport(job.getReport());",
      "return response;",
      "}",
      "privateJobverifyAndGetJob(finalJobId jobID)throwsYarnRemoteException { …",
      "try{ loginUgi = UserGroupInformation.getLoginUser();",
      "job = loginUgi.doAs(newPrivilegedExceptionAction<Job>() {HistoryClientService.java",
      "@Override",
      "publicJob run()throwsException { Job job = history.getJob(jobID);",
      "returnjob;job=null",
      "}",
      "});",
      "}catch(IOException e) {throwRPCUtil.getRemoteException(e);",
      "}catch(InterruptedException e) {throwRPCUtil.getRemoteException(e); }",
      "if(job == null) {throwRPCUtil.getRemoteException(\"Unknown job \"+ jobID);}",
      "JobACL operation = JobACL.VIEW_JOB;",
      "checkAccess(job, operation);",
      "returnjob;",
      "}",
      "public<T>TdoAs(PrivilegedExceptionAction<T> action)throwsIOException, InterruptedException {",
      "try{ logPrivilegedAction(subject, action);",
      "returnSubject.doAs(subject, action);action=null",
      "}catch(PrivilegedActionExceptionpae) {",
      "Throwable cause = pae.getCause();",
      "LOG.error(\"PriviledgedActionException as:\"+this+\" cause:\"+cause);",
      "if(causeinstanceofIOException) {throw(IOException) cause;",
      "}else if(causeinstanceofError) {throw(Error) cause;",
      "}else if(causeinstanceofRuntimeException) {throw(RuntimeException) cause;",
      "}else if(causeinstanceofInterruptedException) {throw(InterruptedException) cause;",
      "}else{throw newUndeclaredThrowableException(pae,\"Unknown exception in doAs\"); }",
      "}",
      "}",
      "",
      "public static<T>TdoAs(finalSubject subject,finaljava.security.PrivilegedExceptionAction<T> action)",
      "throwsjava.security.PrivilegedActionException{Subject.java",
      "java.lang.SecurityManager sm = System.getSecurityManager();",
      "if(sm !=null) { sm.checkPermission(AuthPermissionHolder.DO_AS_PERMISSION); }",
      "if(action == null)throw newNullPointerException",
      "(ResourcesMgr.getString(\"invalid.null.action.provided\"));",
      "",
      "// set up the new Subject-based AccessControlContext for doPrivileged",
      "finalAccessControlContext currentAcc = AccessController.getContext();",
      "",
      "// call doPrivileged and push this new context on the stack",
      "returnjava.security.AccessController.doPrivileged(action,createContext(subject, currentAcc));",
      "} throwPrivilegedActionException",
      "",
      "The following control flow shows whyjob=null",
      "publicJobgetJob(JobId jobId) {JobHistory.java",
      "return storage.getFullJob(jobId);",
      "}",
      "",
      "publicJobgetFullJob(JobId jobId) {CachedHistoryStorage.java",
      "…",
      "try{ HistoryFileInfo fileInfo =hsManager.getFileInfo(jobId);",
      "Job result =null;",
      "…",
      "returnresult;",
      "}catch(IOException e) {throw newYarnException(e); }",
      "}",
      "",
      "publicHistoryFileInfogetFileInfo(JobId jobId)throwsIOException {HistoryFileManager.java",
      "// FileInfo available in cache.",
      "HistoryFileInfo fileInfo = jobListCache.get(jobId);",
      "if(fileInfo !=null) {returnfileInfo; }",
      "",
      "// OK so scan the intermediate to be sure we did not lose it that way",
      "scanIntermediateDirectory();",
      "fileInfo =jobListCache.get(jobId);fileInfo=null",
      "if(fileInfo !=null) {returnfileInfo; }",
      "",
      "// Intermediate directory does not contain job. Search through older ones.",
      "fileInfo = scanOldDirsForJob(jobId);",
      "if(fileInfo !=null) {returnfileInfo; }",
      "returnnull;",
      "}",
      "",
      "",
      "voidscanIntermediateDirectory()throwsIOException {",
      "List<FileStatus> userDirList = JobHistoryUtils.localGlobber(",
      "intermediateDoneDirFc, intermediateDoneDirPath, \"\");",
      "",
      "//Scans the intermediate directory to find user directories. Scans these for history files if the modification time for the directory has changed.",
      "for(FileStatus userDir : userDirList) {",
      "String name = userDir.getPath().getName();",
      "-longnewModificationTime = userDir.getModificationTime();",
      "-booleanshouldScan =false;",
      "-synchronized(userDirModificationTimeMap) {",
      "-if(!userDirModificationTimeMap.containsKey(name)",
      "-||newModificationTime >userDirModificationTimeMap.get(name)) {",
      "-shouldScan =true;befor fixing, the condition doesn’t hold, so “shouldScan=false”",
      "-userDirModificationTimeMap.put(name, newModificationTime);",
      "-}",
      "-}",
      "-if(shouldScan) {",
      "-try{",
      "-scanIntermediateDirectory(userDir.getPath());//scan the specified path",
      "-}catch(IOException e) {",
      "-LOG.error(\"Error while trying to scan the directory\"+ userDir.getPath(), e);",
      "+ UserLogDir dir = userDirModificationTimeMap.get(name);",
      "+ if(dir == null) {",
      "+ dir = new UserLogDir();",
      "+ UserLogDir old = userDirModificationTimeMap.putIfAbsent(name, dir);",
      "+ if(old != null) {",
      "+ dir = old;",
      "}",
      "}",
      "+ dir.scanIfNeeded(userDir);",
      "}",
      "}",
      "",
      "private Map<String, Long>userDirModificationTimeMap= new HashMap<String, Long>();",
      "Maintains a mapping between intermediate user directories and the last known modification time.",
      "Two threads are created in class JobHistory. new ScheduledThreadPoolExecutor (2,",
      "new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\").build());",
      ""
    ]
  },
  "(3) Root Cause": {
    "p": [
      "There is a race condition in the historyserver wheretwo threadscan be trying to scan the same user's done intermediate directory for two separate jobs. One thread will win the race and update the user timestamp inHistoryFileManager.scanIntermediateDirectorybefore it has actually completed the scan. The second thread will then see the timestamp has been updated, think there's no point in doing a scan, and return with no job found."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "This patch has fixed the root cause.",
      "•The patch guarantees there is only one thread scanning the user directory, and updates the modification timeStamp after it really finishes the scanning. So the other scanner thread will scan the specific directory and fine the job information.",
      "• hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
      "This fix adds a private class UserLogDir in the definition of class HistoryFileManager.",
      "The synchronized method scanIfNeeded can guartee there is only one thread scanning the user directory, and updates the modification timeStamp after it really finishes the scanning.",
      "+ /**",
      "+ * This class represents a user dir in the intermediate done directory. This is mostly for locking purposes.",
      "+ */",
      "+ private classUserLogDir{",
      "+ long modTime = 0;// the last known modification time of user directories",
      "+",
      "+ public synchronized voidscanIfNeeded(FileStatus fs) {",
      "+ long newModTime = fs.getModificationTime();",
      "+ if (modTime != newModTime) {",
      "+ Path p = fs.getPath();",
      "+ try {",
      "+ scanIntermediateDirectory(p);",
      "+ //If scanning fails, we will scan again. We assume the failure is temporary.",
      "+ modTime = newModTime;",
      "+ } catch (IOException e) {",
      "+ LOG.error(\"Error while trying to scan the directory \" + p, e);",
      "+ }",
      "+ }",
      "+ }",
      "+ }",
      "",
      "Modify the member variable “userDirModificationTimeMap”in the definition of class HistoryFileManager. Before modification,this variable only maintains a mapping between intermediate user directories and the last known modification time. By using “UserLogDir”, it doesn’t only represent the last known modification time, but also adds locking purpose.",
      "- private Map<String, Long> userDirModificationTimeMap = new HashMap<String, Long>();",
      "+ private ConcurrentMap<String,UserLogDir> userDirModificationTimeMap =",
      "+new ConcurrentHashMap<String, UserLogDir>();",
      "",
      "This fix is marked in the origianl code of method “scanIntermediateDirectory”.",
      "This fix will prevent the situation that one scanner thread updates the user timestamp before it has actually completed the scan. And only one thread can scan the directiry at a time.",
      "@@ -586,23 +610,15 @@ public class HistoryFileManager extends AbstractService {",
      "",
      "for (FileStatus userDir : userDirList) {",
      "String name = userDir.getPath().getName();",
      "- long newModificationTime = userDir.getModificationTime();",
      "- boolean shouldScan = false;",
      "- synchronized (userDirModificationTimeMap) {",
      "- if (!userDirModificationTimeMap.containsKey(name)",
      "- || newModificationTime > userDirModificationTimeMap.get(name)) {",
      "- shouldScan = true;",
      "- userDirModificationTimeMap.put(name, newModificationTime);",
      "- }",
      "- }",
      "- if (shouldScan) {",
      "- try {",
      "- scanIntermediateDirectory(userDir.getPath());",
      "- } catch (IOException e) {",
      "- LOG.error(\"Error while trying to scan the directory \"",
      "- + userDir.getPath(), e);",
      "+ UserLogDir dir = userDirModificationTimeMap.get(name);",
      "+ if(dir == null) {",
      "+ dir = new UserLogDir();",
      "+ UserLogDir old = userDirModificationTimeMap.putIfAbsent(name, dir);",
      "+ if(old != null) {",
      "+ dir = old;",
      "}",
      "}",
      "+ dir.scanIfNeeded(userDir);",
      "}",
      "}"
    ]
  },
  "(5) How many nodes are involved in the patch? (multiple/single node(s))": {
    "p": [
      "One node: history server.",
      ""
    ]
  }
}