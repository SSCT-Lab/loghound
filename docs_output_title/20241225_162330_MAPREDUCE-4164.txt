{
  "p": [
    "MAPREDUCE-4164",
    "Hadoop 22 Exception thrown after task completion causes its reexecution"
  ],
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "mapper/reducer: client-side TaskTracker: server-side",
        "All of them are in one node. Although each slave node has only one TaskTracker, each TT can generate multiple JVMs, and running several map/reduce tasks simultaneously."
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "2012-02-28 19:17:08,504 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 1969310 bytes",
        "2012-02-28 19:17:08,694 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000094_0 is done. And isin the process of commiting",
        "2012-02-28 19:18:08,774 INFO org.apache.hadoop.mapred.Task:Communication exception: java.io.IOException: Call to /127.0.0.1:35400 failed on local exception: java.nio.channels.ClosedByInterruptException",
        "at org.apache.hadoop.ipc.Client.wrapException(Client.java:1094)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1062)",
        "at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)",
        "at $Proxy0.statusUpdate(Unknown Source)",
        "at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:650)",
        "at java.lang.Thread.run(Thread.java:662)",
        "Caused by: java.nio.channels.ClosedByInterruptException",
        "at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)",
        "at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)",
        "at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:60)",
        "at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)",
        "at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:151)",
        "at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:112)",
        "at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)",
        "at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)",
        "at java.io.DataOutputStream.flush(DataOutputStream.java:106)",
        "at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:769)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1040)",
        "... 4 more",
        "2012-02-28 19:18:08,825 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000094_0' done.",
        "================>>>>>> SHOULD be <++++++++++++++",
        "2012-02-28 19:17:02,214 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 1974104 bytes",
        "2012-02-28 19:17:02,408 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000000_0 is done. And is in the process of commiting",
        "2012-02-28 19:17:02,519 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000000_0' done."
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "(a) In map/reduce task, TaskReporter thread sends status updates/pings periodically to TaskTracker.",
      "• If it needs to send the task progress, it sends STATUS_UPDATE message to TaskTracker.",
      "• Otherwise, it sends a PING signal to check if the TaskTracker is alive.",
      "(b) When the map/reduce phase is over, it calls stopCommunicationThread() which interrupts ping/statusupdate thread.",
      "The second log info item posted above is",
      "2012-02-28 19:17:08,694 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000094_0 is done. And is in the process of commiting",
      "The log shows that a map task is done. When the map task is done, it will waitinig to commit to HDFS.",
      "notes:TaskUmbilicalProtocol is used for RPC communication between map/reduce task and its parent (here, this bug is related to Hadoop 1.0, its parent refers to TaskTracker; In Hadoop 2.0, its parent refers to AM).",
      "The control flow of this bug is as follows:",
      "• umbilical.statusUpdate() is used for sending progress to TT;",
      "• connection.sendParam(call) is used for sending the parameter to the remote server (TT).",
      "• ClosedByInterruptException: received by a thread when another thread interrupts it while it is blocked in an I/O operation upon a channel.",
      ""
    ]
  },
  "(3) Root Cause": {
    "p": [
      "When the map/reduce phase is finished (here, it refers that the mapper finishes committing the result to HDFS), stopCommunicationThread() will be called in MapTask.run(), and interrupt the communication(ping/statusupdate) thread. At this time, if the map task is still communicating wilth TT through this ping/statusupdate thread, the interruption will break the connection between the task and TT. So the DataOutputStream (used by sending parameter) will be closed, and it leads to the “ClosedByInterruptException”."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "· mapreduce/src/java/org/apache/hadoop/mapred/Task.java",
      "Fix the root cause.",
      "The patch adds a synchronization mechanism for the communication thread. When the communication thread is still communicating with TT, it will not be interrupted in MapTask, so “ClosedByInterruptException” will not happen.",
      "The fixes are in the communication thread, i.e. TaskReporter.run().",
      "The following fixes are also marked in the last part of this ducument: (6) code snippets.",
      "@@ -536,6 +536,8 @@",
      "private InputSplit split = null;",
      "private Progress taskProgress;",
      "private Thread pingThread = null;",
      "+ private boolean done = true;class TaskReporter is defined in Task.java. Add a member “lock” in this class, it is used for synchronization.",
      "+ private Object lock = new Object();",
      "",
      "/**",
      "* flag that indicates whether progress update needs to be sent to parent.",
      "@@ -627,6 +629,9 @@",
      "// get current flag value and reset it as well",
      "boolean sendProgress = resetProgressFlag();",
      "while (!taskDone.get()) {",
      "+ synchronized (lock) {As long as current task is not finished, set “done=false” at the beginning in each loop.",
      "+ done = false;",
      "+ }",
      "try {",
      "boolean taskFound = true; // whether TT knows about this task",
      "// sleep for a bit",
      "@@ -659,6 +664,7 @@",
      "// came back up), kill ourselves",
      "if (!taskFound) {",
      "LOG.warn(\"Parent died. Exiting \"+taskId);",
      "+ resetDoneFlag();",
      "System.exit(66);",
      "}",
      "",
      "@@ -671,11 +677,22 @@",
      "if (remainingRetries == 0) {",
      "ReflectionUtils.logThreadInfo(LOG, \"Communication exception\", 0);",
      "LOG.warn(\"Last retry, killing \"+taskId);",
      "+ resetDoneFlag();",
      "System.exit(65);",
      "}",
      "}",
      "}",
      "+ //Notify that we are done with the work",
      "+ resetDoneFlag();",
      "}",
      "+",
      "+ void resetDoneFlag() {",
      "+ synchronized (lock) {",
      "+ done = true;",
      "+ lock.notify();When the taskReporter really finishes the communication task, “lock.notify()” will wake up the “lock.wait()”, then the communication thread can be interrupted.",
      "+ }",
      "+ }",
      "+",
      "public void startCommunicationThread() {",
      "if (pingThread == null) {",
      "pingThread = new Thread(this, \"communication thread\");",
      "@@ -685,6 +702,11 @@",
      "}",
      "public void stopCommunicationThread() throws InterruptedException {",
      "",
      "if (pingThread != null) {",
      "+ synchronized (lock) {it will wait till “lock.notify” wakes it up.",
      "+ while (!done) {",
      "+ lock.wait();",
      "+ }",
      "+ }",
      "pingThread.interrupt();",
      "pingThread.join();",
      "}"
    ]
  },
  "(5) How many nodes are involved in the patch? (multiple/single node(s))": {
    "p": [
      "Both Class MapTask and Class ReduceTask extend from Class Task(Task.java), and they will get the object TaskReporter from Task.java. So the fixes in Task.java will act on every Map/Reduce task. When running a job, there may be several mapper and reducers (running on multiple node), so the fixes will affect multiple nodes.",
      ""
    ]
  },
  "(6) Code Snippets": {
    "p": [
      "Based on the call-stack and the source code, we can get the following call relationship:",
      "MapTask.run(){ ……",
      "TaskReporter reporter =startReporter(umbilical);",
      "……",
      "done(umbilical, reporter);",
      "}",
      "",
      "******",
      "public voiddone(TaskUmbilicalProtocol umbilical, TaskReporter reporter)",
      "throwsIOException, InterruptedException {",
      "LOG.info(\"Task:\"+taskId+\" is done.\"+\" And is in the process of commiting\");",
      "updateCounters();",
      "booleancommitRequired = isCommitRequired();",
      "if(commitRequired) {……",
      "//wait for commit approval and commit",
      "commit(umbilical, reporter, committer);",
      "}",
      "taskDone.set(true);",
      "reporter.stopCommunicationThread();",
      "// Make sure we send at least one set of counter increments.",
      "//It’s ok to call updateCounters() in this thread after comm thread stopped.",
      "updateCounters();",
      "sendLastUpdate(umbilical);",
      "//signal the tasktracker that we are done",
      "sendDone(umbilical);",
      "}",
      "",
      "public voidstopCommunicationThread()throwsInterruptedException {",
      "if(pingThread!=null) {",
      "+ synchronized (lock) {",
      "+ while (!done) {",
      "+ lock.wait();",
      "+ }",
      "+ }",
      "",
      "pingThread.interrupt();",
      "pingThread.join();",
      "}",
      "}",
      "",
      "private voidsendDone(TaskUmbilicalProtocol umbilical)throwsIOException {",
      "intretries =MAX_RETRIES;",
      "while(true) {",
      "try{",
      "umbilical.done(getTaskID());",
      "LOG.info(\"Task '\"+taskId+\"' done.\");return;",
      "}catch(IOException ie) {",
      "LOG.warn(\"Failure signalling completion: \"+ StringUtils.stringifyException(ie));",
      "if(--retries ==0) {throwie; }",
      "}",
      "}",
      "}",
      "******",
      "TaskReporterstartReporter(finalTaskUmbilicalProtocol umbilical) {Task.java",
      "// start thread that will handle communication with parent TT",
      "TaskReporter reporter =newTaskReporter(getProgress(), umbilical);",
      "reporter.startCommunicationThread();",
      "returnreporter;",
      "}",
      "",
      "public voidstartCommunicationThread() {",
      "if(pingThread==null) {",
      "pingThread=newThread(this,\"communication thread\");",
      "pingThread.setDaemon(true);",
      "pingThread.start();",
      "}",
      "}",
      "",
      "TaskReporter.run() { ……Task.java The fix works here.",
      "final intMAX_RETRIES =3;",
      "intremainingRetries = MAX_RETRIES;",
      "// get current flag value and reset it as well",
      "booleansendProgress = resetProgressFlag();",
      "while(!taskDone.get()) {",
      "+ synchronized (lock) {",
      "+ done = false;",
      "+ }",
      "try{",
      "booleantaskFound =true; // whether TT knows about this task",
      "// sleep for a bit",
      "……",
      "if(sendProgress) {",
      "// we need to send progress update",
      "updateCounters();",
      "taskStatus.statusUpdate(taskProgress.get(), taskProgress.toString(), counters);",
      "taskFound =umbilical.statusUpdate(taskId, taskStatus);Due to the RPC mechanism in Hadoop, when the client call some method of TaskUmbilicalProtocol, it will jump to “invoke” method, which implements the InvocationHandler interface.",
      "taskStatus.clearStatus();",
      "}",
      "else{ // send ping",
      "taskFound =umbilical.ping(taskId);",
      "}",
      "",
      "// if Task Tracker is not aware of our task ID (probably because it died and",
      "// came back up), kill ourselves",
      "if(!taskFound) {",
      "LOG.warn(\"Parent died. Exiting “+taskId);",
      "+ resetDoneFlag();",
      "System.exit(66);",
      "}",
      "sendProgress = resetProgressFlag();",
      "remainingRetries = MAX_RETRIES;",
      "}",
      "catch(Throwable t) {",
      "LOG.info(\"Communication exception: \"+ StringUtils.stringifyException(t));",
      "remainingRetries -=1;",
      "if(remainingRetries ==0) {",
      "ReflectionUtils.logThreadInfo(LOG, \"Communication exception\", 0);",
      "LOG.warn(\"Last retry, killing \"+taskId);",
      "+ resetDoneFlag();",
      "System.exit(65);",
      "}",
      "}",
      "} //while",
      "+ //Notify that we are done with the work",
      "+ resetDoneFlag();",
      "}",
      "+",
      "+ void resetDoneFlag() {",
      "+ synchronized (lock) {",
      "+ done = true;",
      "+ lock.notify();",
      "+ }",
      "+ }",
      "+",
      "",
      "WritableRpcEngine.java",
      "publicObjectinvoke(Object proxy, Method method, Object[] args)throwsThrowable{",
      "……",
      "ObjectWritable value = (ObjectWritable)client.call(newInvocation(method, args),remoteId);",
      "……",
      "}",
      "",
      "Client.java",
      "//Make a call, passing param, to the IPC server defined by remoteId, returning the value.",
      "//Throws exceptions if there are network problems or if the remote code throws an exception.",
      "publicWritablecall(Writable param, ConnectionId remoteId)throwsInterruptedException, IOException {",
      "Call call =newCall(param);",
      "Connection connection = getConnection(remoteId, call);",
      "connection.sendParam(call); // send the parametergenerate ClosedByInterruptException: received by a thread when another thread interrupts it while it is blocked in an I/O operation upon a channel.",
      "booleaninterrupted =false;",
      "synchronized(call) {",
      "while(!call.done) {",
      "try{ call.wait(); // wait for the result",
      "} catch (InterruptedException ie) { // save the fact that we were interrupted",
      "interrupted =true;",
      "}",
      "}",
      "if(interrupted) { // set the interrupt flag now that we are done waiting",
      "Thread.currentThread().interrupt();",
      "}",
      "if(call.error!=null) {",
      "if(call.errorinstanceofRemoteException) { call.error.fillInStackTrace();throwcall.error;",
      "}else{ // local exception",
      "throwwrapException(remoteId.getAddress(), call.error);",
      "}",
      "}else{returncall.value; }",
      "}",
      "}",
      "",
      "privateIOExceptionwrapException(InetSocketAddress addr, IOException exception) {",
      "if(exceptioninstanceofConnectException) { //connection refused; include the host:port in the error",
      "return(ConnectException)newConnectException(",
      "\"Call to \" + addr + \" failed on connection exception: \" + exception).initCause(exception);",
      "} else if (exception instanceof SocketTimeoutException) {",
      "return (SocketTimeoutException)new SocketTimeoutException(",
      "\"Call to \" + addr + \" failed on socket timeout exception: \" + exception).initCause(exception);",
      "}else{return(IOException)newIOException(",
      "\"Call to \"+ addr +\" failed on local exception: \"+ exception).initCause(exception);",
      "}",
      "}",
      "",
      ""
    ]
  }
}