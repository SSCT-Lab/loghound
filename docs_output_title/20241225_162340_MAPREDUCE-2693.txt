{
  "p": [
    "MAPREDUCE-2693",
    "NPE in AM causes it to lose containers which are never returned back to RM"
  ],
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "AM (Client-side) RM(server-side)"
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "Once the following exception happens, AM keeps obtaining containers from RM and simply loses them. Eventually on a cluster with multiple jobs, no more scheduling happens because of these lost containers.",
        "AM’s log",
        "11/06/17 06:11:18 INFO rm.RMContainerAllocator:Assigned based on host match98.138.163.34",
        "11/06/17 06:11:18 INFO rm.RMContainerRequestor: BEFORE decResourceRequest: applicationId=30 priority=20",
        "resourceName=... numContainers=4978 #asks=5",
        "11/06/17 06:11:18 INFO rm.RMContainerRequestor: AFTER decResourceRequest: applicationId=30 priority=20",
        "resourceName=... numContainers=4977 #asks=5",
        "11/06/17 06:11:18 INFO rm.RMContainerRequestor: BEFORE decResourceRequest: applicationId=30 priority=20",
        "resourceName=... numContainers=1540 #asks=5",
        "11/06/17 06:11:18 INFO rm.RMContainerRequestor: AFTER decResourceRequest: applicationId=30 priority=20",
        "resourceName=... numContainers=1539 #asks=6",
        "11/06/17 06:11:18 ERROR rm.RMContainerAllocator:ERROR IN CONTACTING RM.",
        "java.lang.NullPointerException",
        "at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.decResourceRequest(RMContainerRequestor.java:246)",
        "at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.decContainerReq(RMContainerRequestor.java:198)",
        "at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:523)",
        "at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$200(RMContainerAllocator.java:433)",
        "at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:151)",
        "at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:220)",
        "at java.lang.Thread.run(Thread.java:619)"
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "In AM,",
      "RMCommunicator is responsible for registers/unregisters to RM and sending heartbeats to RM.",
      "RMCommunicator is RMContainerAllocator’s final parent class.",
      "RMContainerAllocator is responsible for allocating the container from the ResourceManager scheduler.",
      "",
      "When AM starts, it will register itself to RM and start allocator thread to send heartbeats to RM.",
      "The heartbeat is not only to inform RM that AM is alive, but also apply/release the container resource from/to RM.",
      "We can get the following control flow based on the log and source code.",
      "",
      "",
      "",
      "Based on the following source code of method decResourceRequest(), I think the object “this.remoteRequestsTable” or “remoteRequest” may be null, which leads to NPE.",
      "",
      "",
      "RMContainerRequestor.javajava.lang.NullPointerException",
      "private voiddecResourceRequest(Priority priority, String resourceName,Resource capability) {",
      "Map<String, Map<Resource, ResourceRequest>>remoteRequests=this.remoteRequestsTable.get(priority);",
      "Map<Resource, ResourceRequest> reqMap = remoteRequests.get(resourceName);",
      "if(reqMap ==null) {",
      "// as we modify the resource requests by filtering out blacklisted hosts",
      "// when they are added, this value may be null when being decremented",
      "LOG.debug(\"Not decrementing resource as \"+ resourceName +\" is not present in request table\");",
      "return;",
      "}",
      "ResourceRequest remoteRequest = reqMap.get(capability);",
      "",
      "LOG.info(\"BEFORE decResourceRequest:\"+\" applicationId=\"+applicationId.getId()",
      "+\" priority=\"+ priority.getPriority() +\" resourceName=\"+ resourceName",
      "+\" numContainers=\"+ remoteRequest.getNumContainers() +\" #asks=“+ask.size());",
      "",
      "remoteRequest.setNumContainers(remoteRequest.getNumContainers() -1);",
      "if(remoteRequest.getNumContainers() ==0) {",
      "reqMap.remove(capability);",
      "if(reqMap.size() ==0) { remoteRequests.remove(resourceName); }",
      "if(remoteRequests.size() ==0) {remoteRequestsTable.remove(priority); }",
      "//remove from ask if it may have",
      "ask.remove(remoteRequest);",
      "}else{ask.add(remoteRequest); //this will override the request if ask doesn’t already have it.",
      "}",
      "LOG.info(\"AFTER decResourceRequest:\"+\" applicationId=“+applicationId.getId()",
      "+\" priority=\"+ priority.getPriority() +\" resourceName=\"+ resourceName",
      "+\" numContainers=“+ remoteRequest.getNumContainers() +\" #asks=\"+ask.size());",
      "}",
      "",
      "“remoteRequestsTable” is a member variable of class RMContainerRequestor, and I find that in file “RMContainerRequestor.java”, the method “voidcontainerFailedOnHost(String hostName)",
      "” can modify the variable “remoteRequestsTable”, and move the remote request from this table.",
      "",
      "According to the descrition in this bug report: The real problem is that when NPE happens, AM will keep obtaining containers from RM and simply loses them. This happens only when there are blacklisted nodes at the app level in AM(i.e. job level blacknode is enable).",
      "And the bug in AM (RMContainerRequestor.containerFailedOnHost(hostName)) causes this: nodes are simply getting removed from the request-table, but RM doesn’t know this update."
    ]
  },
  "(3) Root Cause": {
    "p": [
      "When a hostname has been added to the blacklist, all the requests corresponding to this hostname are removed from remoteRequestsTable directly without checking whether some requests on this host have been sent to RM, so RM doesn’t know this update.",
      "The cause of NPE is not mentioned in the bug report, and I have written my understanding about this cause in part (4)."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "The real cause is fixed.",
      "Several methods in files RMContainerAllocator.java and RMContainerRequestor.java have been made a big change. The main fixes are in the method (a) “void assign(List<Container> allocatedContainers)” and (b) “void containerFailedOnHost(String hostName)”.",
      "",
      "For(a)“void assign(List<Container> allocatedContainers)”, after the fix,",
      "• when assigning a container to the task, it will check whether allocated container meets memory requirements and whether we have any scheduled tasks that need a container to be assigned;",
      "• if the container meets the above conditions, it will check whether the allocated container is on a blacklisted host.",
      "- if the allocated container is on a blacklisted host, we need to request for a new container and release the current one",
      "- else we can assign this allocated container to the task, then update resource requests,i.e. decrease the container requests.",
      "- To my understanding about the NPE: Before this fix, when assigning a container to the task, it doesn’t do the blacklisted host check, i.e. it doesn’t check whether the allocated container is on a blacklisted host. And it assigns the “wrong” container to the task, then decreases the container request from remoteRequestsTable. It happens that the host running this container has just been added to the blacklist, and containerFailedOnHost will remove all the requests corresponding to this hostname. At the same time, the containers in current remoteRequestsTable are all from this host (since in container request, use can appoint the expected host). So remoteRequestsTable becomes null, and when invoking this object’s method, NPE will happen.",
      "",
      "For(b)“void containerFailedOnHost(String hostName)”,",
      "This method is called by event handler inRMContainerAllocator.java",
      "public synchronized voidhandle(ContainerAllocatorEvent event) {",
      "LOG.info(\"Processing the event \"+ event.toString());",
      "recalculateReduceSchedule=true;",
      "if(event.getType() == ContainerAllocator.EventType.CONTAINER_REQ) { … }",
      "else if(event.getType() == ContainerAllocator.EventType.CONTAINER_DEALLOCATE) {… }",
      "else if( event.getType() == ContainerAllocator.EventType.CONTAINER_FAILED) {",
      "ContainerFailedEvent fEv = (ContainerFailedEvent) event;",
      "String host =getHost(fEv.getContMgrAddress());",
      "containerFailedOnHost(host);",
      "}",
      "}",
      "before the fix, when a hostname is added to the blacklist, this method remove all the requests corresponding to this hostname from remoteRequestsTable directly without checking whether some requests on this host have been sent to RM.",
      "After the fix, if the requests that on this host have been sent to RM, we will overwrite it by sending a new request to RM with numContainers specified for the blacklisted host to be 0.",
      "",
      "(a) inRMContainerAllocator.java",
      "private voidassign(List<Container> allocatedContainers) {",
      "Iterator<Container> it = allocatedContainers.iterator();",
      "LOG.info(\"Got allocated containers \"+ allocatedContainers.size());",
      "containersAllocated+= allocatedContainers.size();",
      "while(it.hasNext()) {",
      "Container allocated = it.next();",
      "LOG.info(\"Assigning container \"+ allocated);",
      "-ContainerRequest assigned = assign(allocated);",
      "-",
      "-if (assigned != null) {",
      "-// Update resource requests",
      "-decContainerReq(assigned);",
      "+",
      "+// check if allocated container meets memory requirements",
      "+// and whether we have any scheduled tasks that need",
      "+// a container to be assigned",
      "+booleanisAssignable =true;",
      "+Priority priority = allocated.getPriority();",
      "+if(PRIORITY_FAST_FAIL_MAP.equals(priority)",
      "+||PRIORITY_MAP.equals(priority)) {",
      "+if(allocated.getResource().getMemory() <mapResourceReqt",
      "+||maps.isEmpty()) {",
      "+LOG.info(\"Cannot assign container \"+ allocated",
      "++\" for a map as either “",
      "++\" container memory less than required \"+mapResourceReqt",
      "++\" or no pending map tasks - maps.isEmpty=\"",
      "++maps.isEmpty());",
      "+isAssignable =false;",
      "+}",
      "+}",
      "+else if(PRIORITY_REDUCE.equals(priority)) {",
      "+if(allocated.getResource().getMemory() <reduceResourceReqt",
      "+||reduces.isEmpty()) {",
      "+LOG.info(\"Cannot assign container \"+ allocated",
      "++\" for a reduce as either “",
      "++\" container memory less than required \"+reduceResourceReqt",
      "++\" or no pending reduce tasks - reduces.isEmpty=“",
      "++reduces.isEmpty());",
      "+isAssignable =false;",
      "+}",
      "+}",
      "+",
      "+booleanblackListed =false;",
      "+ContainerRequest assigned =null;",
      "+if(isAssignable) {",
      "+// do not assign if allocated container is on a",
      "+// blacklisted host",
      "+blackListed = isNodeBlacklisted(allocated.getNodeId().getHost());",
      "+if(blackListed) {",
      "+// we need to request for a new container",
      "+// and release the current one",
      "+LOG.info(\"Got allocated container on a blacklisted “",
      "++\" host. Releasing container \"+ allocated);",
      "+",
      "+// find the request matching this allocated container",
      "+// and replace it with a new one",
      "+ContainerRequest toBeReplacedReq =",
      "+getContainerReqToReplace(allocated);",
      "+if(toBeReplacedReq !=null) {",
      "+LOG.info(\"Placing a new container request for task attempt \"",
      "++ toBeReplacedReq.attemptID);",
      "+ContainerRequest newReq =",
      "+getFilteredContainerRequest(toBeReplacedReq);",
      "+decContainerReq(toBeReplacedReq);",
      "+if(toBeReplacedReq.attemptID.getTaskId().getTaskType() ==",
      "+TaskType.MAP) {",
      "+maps.put(newReq.attemptID, newReq);",
      "+}",
      "+else{",
      "+reduces.put(newReq.attemptID, newReq);",
      "+}",
      "+addContainerReq(newReq);",
      "+}",
      "+else{",
      "+LOG.info(\"Could not map allocated container to a valid request.”",
      "++\" Releasing allocated container \"+ allocated);",
      "+}",
      "+}",
      "+else{",
      "+assigned = assign(allocated);",
      "+if(assigned !=null) {",
      "+// Update resource requests",
      "+decContainerReq(assigned);",
      "",
      "-// send the container-assigned event to task attempt",
      "-eventHandler.handle(newTaskAttemptContainerAssignedEvent(",
      "-assigned.attemptID, allocated));",
      "+The code in blue region are not changed in semantic.",
      "+// send the container-assigned event to task attempt",
      "+eventHandler.handle(newTaskAttemptContainerAssignedEvent(",
      "+assigned.attemptID, allocated,applicationACLs));",
      "",
      "-assignedRequests.add(allocated.getId(), assigned.attemptID);",
      "-",
      "-LOG.info(\"Assigned container (\" + allocated + \") \" +",
      "-\" to task \" + assigned.attemptID +",
      "-\" on node \" + allocated.getNodeId().toString());",
      "-} else {",
      "-//not assigned to any request, release the container",
      "-LOG.info(\"Releasing unassigned and invalid container \" + allocated",
      "-+ \". RM has gone crazy, someone go look!\"",
      "-+ \" Hey RM, if you are so rich, go donate to non-profits!”);",
      "+assignedRequests.add(allocated.getId(), assigned.attemptID);",
      "+",
      "+LOG.info(\"Assigned container (\"+ allocated +\") \"+",
      "+\" to task \"+ assigned.attemptID+",
      "+\" on node \"+ allocated.getNodeId().toString());",
      "+}",
      "+else{",
      "+//not assigned to any request, release the container",
      "+LOG.info(\"Releasing unassigned and invalid container “",
      "++ allocated +\". RM has gone crazy, someone go look!”",
      "++\" Hey RM, if you are so rich, go donate to non-profits!”);",
      "+}",
      "+}",
      "+}",
      "+// release container if it was blacklisted",
      "+// or if we could not assign it",
      "+if(blackListed || assigned ==null) {",
      "containersReleased++; release(allocated.getId()); }",
      "}",
      "}",
      "",
      "(b) inRMContainerRequestor.java",
      "protected voidcontainerFailedOnHost(String hostName) {",
      "if(!nodeBlacklistingEnabled) {return; }",
      "if(blacklistedNodes.contains(hostName)) {LOG.info(\"Host \"+ hostName +\" is already blacklisted.\");",
      "return;//already blacklisted",
      "}",
      "Integer failures =nodeFailures.remove(hostName);",
      "failures = failures ==null?0: failures;",
      "failures++;",
      "LOG.info(failures +\" failures on node \"+ hostName);",
      "if(failures >=maxTaskFailuresPerNode) {blacklistedNodes.add(hostName);",
      "LOG.info(\"Blacklisted host \"+ hostName);",
      "",
      "//remove all the requests corresponding to this hostname",
      "for(Map<String, Map<Resource, ResourceRequest>> remoteRequests",
      ":remoteRequestsTable.values()){",
      "-//remove from host",
      "-Map<Resource, ResourceRequest> reqMap = remoteRequests.remove(hostName);",
      "+//remove from host if no pending allocations",
      "+booleanfoundAll =true;",
      "+Map<Resource, ResourceRequest> reqMap = remoteRequests.get(hostName);",
      "if(reqMap !=null) {",
      "for(ResourceRequest req : reqMap.values()) {",
      "-ask.remove(req);AM “loses” the containers without informing RM.",
      "+if(!ask.remove(req)) {",
      "+",
      "foundAll =false;",
      "+// if ask already sent to RM, we can try and overwrite it if possible.",
      "+// send a new ask to RM with numContainers",
      "+// specified for the blacklisted host to be 0.",
      "+ResourceRequest zeroedRequest = BuilderUtils.newResourceRequest(req);",
      "+zeroedRequest.setNumContainers(0);",
      "+// to be sent to RM on next heartbeat",
      "+ask.add(zeroedRequest);",
      "+}",
      "+}",
      "+// if all requests were still in ask queue",
      "+// we can remove this request",
      "+if(foundAll) {",
      "+remoteRequests.remove(hostName);",
      "+}",
      "}",
      "+//TODO handling of rack blacklisting",
      "+// Removing from rack should be dependent on no. of failures within the rack",
      "+// Blacklisting a rack on the basis of a single node's blacklisting",
      "+// may be overly aggressive.",
      "+// Node failures could be co-related with other failures on the same rack",
      "+// but we probably need a better approach at trying to decide how and when",
      "+// to blacklist a rack",
      "}",
      "}else{nodeFailures.put(hostName, failures); }",
      "}",
      ""
    ]
  },
  "(5) How many nodes are involved in the patch? (multiple/single node(s))": {
    "p": [
      "All the fixes are in AM."
    ]
  },
  "(6) Code Snippets": {
    "p": [
      "RMCommunicator.java",
      "public voidstart() {",
      "scheduler= createSchedulerProxy();//get RM proxy",
      "//LOG.info(\"Scheduler is \" + scheduler);",
      "register();",
      "startAllocatorThread();// thread for heartbeat",
      "JobID id = TypeConverter.fromYarn(context.getApplicationID());",
      "JobId jobId = TypeConverter.toYarn(id);",
      "job=context.getJob(jobId);",
      "super.start();",
      "}",
      "RMCommunicator.java",
      "protected voidstartAllocatorThread() {",
      "allocatorThread=newThread(newRunnable() {",
      "@Override",
      "public voidrun() {",
      "while(!stopped&& !Thread.currentThread().isInterrupted()) {",
      "try{ Thread.sleep(rmPollInterval);",
      "try{heartbeat();",
      "}catch(YarnException e) {LOG.error(\"Error communicating with RM:\"+ e.getMessage() , e);",
      "return;",
      "}catch(Exception e) {LOG.error(\"ERROR IN CONTACTING RM.\", e);",
      "//TODO: for other exceptions}",
      "}catch(InterruptedException e) {LOG.info(\"Allocated thread interrupted. Returning.\");return; }",
      "}",
      "}",
      "});",
      "allocatorThread.setName(\"RMCommunicator Allocator\");",
      "allocatorThread.start();",
      "}",
      "",
      "protected synchronized voidheartbeat()throwsException {RMContainerAllocator.java",
      "LOG.info(\"Before Scheduling: \"+ getStat());",
      "List<Container> allocatedContainers = getResources();//send heartbeat to RM, and handle response",
      "LOG.info(\"After Scheduling: \"+ getStat());",
      "if(allocatedContainers.size() >0) {",
      "LOG.info(\"Before Assign: \"+ getStat());",
      "scheduledRequests.assign(allocatedContainers);//assign the container to the task",
      "LOG.info(\"After Assign: \"+ getStat());",
      "}",
      "if(recalculateReduceSchedule) {",
      "preemptReducesIfNeeded();",
      "scheduleReduces();",
      "recalculateReduceSchedule=false;",
      "}",
      "}",
      "",
      "According to the first info in log, we can localize the code point:",
      "11/06/17 06:11:18 INFO rm.RMContainerAllocator: Assigned based on host match 98.138.163.34",
      "assignToMapis called, and the return value !=null",
      "privateContainerRequestassignToMap(Container allocated) {",
      "//try to assign to maps if present first by host, then by rack, followed by *",
      "ContainerRequest assigned =null;",
      "while(assigned ==null&&maps.size() >0) {",
      "String host = allocated.getNodeId().getHost();",
      "LinkedList<TaskAttemptId> list =mapsHostMapping.get(host);",
      "while(list !=null&& list.size() >0) {",
      "LOG.info(\"Host matched to the request list\"+ host);",
      "TaskAttemptId tId = list.removeFirst();",
      "if(maps.containsKey(tId)) {",
      "assigned =maps.remove(tId);",
      "JobCounterUpdateEvent jce =",
      "newJobCounterUpdateEvent(assigned.attemptID.getTaskId().getJobId());",
      "jce.addCounterUpdate(JobCounter.DATA_LOCAL_MAPS,1);",
      "eventHandler.handle(jce);",
      "hostLocalAssigned++;",
      "LOG.info(\"Assigned based on host match \"+ host);",
      "break;",
      "}",
      "}",
      "if(assigned ==null) { … }",
      "if(assigned ==null&&maps.size() >0) { … }",
      "returnassigned;",
      "}",
      "",
      "assignToMapis called byassign, and the return value !=null",
      "privateContainerRequestassign(Container allocated) {",
      "ContainerRequest assigned =null;",
      "",
      "Priority priority = allocated.getPriority();",
      "if(PRIORITY_FAST_FAIL_MAP.equals(priority)) {",
      "LOG.info(\"Assigning container \"+ allocated +\" to fast fail map\");",
      "assigned = assignToFailedMap(allocated);",
      "}else if(PRIORITY_REDUCE.equals(priority)) {",
      "LOG.info(\"Assigning container \"+ allocated +\" to reduce\");",
      "assigned = assignToReduce(allocated);",
      "}else if(PRIORITY_MAP.equals(priority)) {",
      "LOG.info(\"Assigning container \"+ allocated +\" to map\");",
      "assigned =assignToMap(allocated);",
      "}else{LOG.warn(\"Container allocated at unwanted priority: \"+ priority +\". Returning to RM...\");",
      "}",
      "returnassigned;",
      "}",
      "",
      "assignis called by the followingassign, which is called in hearbeat()",
      "private voidassign(List<Container> allocatedContainers) {",
      "Iterator<Container> it = allocatedContainers.iterator();",
      "LOG.info(\"Got allocated containers \"+ allocatedContainers.size());",
      "containersAllocated+= allocatedContainers.size();",
      "while(it.hasNext()) {",
      "Container allocated = it.next();",
      "LOG.info(\"Assigning container \"+ allocated);",
      "",
      "// check if allocated container meets memory requirements",
      "// and whether we have any scheduled tasks that need a container to be assigned",
      "booleanisAssignable =true;",
      "Priority priority = allocated.getPriority();",
      "…",
      "booleanblackListed =false;",
      "ContainerRequest assigned =null;",
      "",
      "if(isAssignable) {",
      "// do not assign if allocated container is on a blacklisted host",
      "if(blackListed) { … }",
      "else{",
      "assigned =assign(allocated);//assigned != null",
      "if(assigned !=null) { // Update resource requests",
      "decContainerReq(assigned);",
      "// send the container-assigned event to task attempt",
      "…",
      "}",
      "else{ //not assigned to any request, release the container…}",
      "}",
      "}",
      "// release container if it was blacklisted or if we could not assign it",
      "if(blackListed || assigned ==null) {containersReleased++;",
      "release(allocated.getId());",
      "}",
      "}",
      "}",
      "RMContainerRequestor.java",
      "protected voiddecContainerReq(ContainerRequest req) {",
      "// Update resource requests",
      "for(String hostName : req.hosts) {decResourceRequest(req.priority, hostName, req.capability); }",
      "for(String rack : req.racks) { decResourceRequest(req.priority, rack, req.capability); }",
      "decResourceRequest(req.priority,ANY, req.capability);",
      "}",
      "",
      "private voiddecResourceRequest(Priority priority, String resourceName,Resource capability) {",
      "Map<String, Map<Resource, ResourceRequest>> remoteRequests =this.remoteRequestsTable.get(priority);",
      "Map<Resource, ResourceRequest> reqMap = remoteRequests.get(resourceName);",
      "if(reqMap ==null) {",
      "// as we modify the resource requests by filtering out blacklisted hosts",
      "// when they are added, this value may be null when being decremented",
      "LOG.debug(\"Not decrementing resource as \"+ resourceName +\" is not present in request table\");",
      "return;",
      "}",
      "ResourceRequest remoteRequest = reqMap.get(capability);",
      "",
      "LOG.info(\"BEFORE decResourceRequest:\"+\" applicationId=\"+applicationId.getId()",
      "+\" priority=\"+ priority.getPriority() +\" resourceName=\"+ resourceName",
      "+\" numContainers=\"+ remoteRequest.getNumContainers() +\" #asks=“+ask.size());",
      "",
      "remoteRequest.setNumContainers(remoteRequest.getNumContainers() -1);",
      "if(remoteRequest.getNumContainers() ==0) {",
      "reqMap.remove(capability);",
      "if(reqMap.size() ==0) { remoteRequests.remove(resourceName); }",
      "if(remoteRequests.size() ==0) {remoteRequestsTable.remove(priority); }",
      "//remove from ask if it may have",
      "ask.remove(remoteRequest);",
      "}else{ask.add(remoteRequest); //this will override the request if ask doesn’t already have it. }",
      "",
      "LOG.info(\"AFTER decResourceRequest:\"+\" applicationId=\"",
      "+applicationId.getId() +\" priority=\"+ priority.getPriority()",
      "+\" resourceName=\"+ resourceName +\" numContainers=\"",
      "+ remoteRequest.getNumContainers() +\" #asks=\"+ask.size());",
      "}",
      "",
      "protected voidcontainerFailedOnHost(String hostName) { // this is the fixed code",
      "if(!nodeBlacklistingEnabled) {return; }",
      "if(blacklistedNodes.contains(hostName)) {LOG.info(\"Host \"+ hostName +\" is already blacklisted.\");",
      "return; //already blacklisted",
      "}",
      "Integer failures =nodeFailures.remove(hostName);",
      "failures = failures ==null?0: failures;",
      "failures++;",
      "LOG.info(failures +\" failures on node \"+ hostName);",
      "if(failures >=maxTaskFailuresPerNode) {blacklistedNodes.add(hostName);",
      "LOG.info(\"Blacklisted host \"+ hostName);",
      "",
      "//remove all the requests corresponding to this hostname",
      "for(Map<String, Map<Resource, ResourceRequest>> remoteRequests",
      ":remoteRequestsTable.values()){",
      "//remove from host if no pending allocations",
      "booleanfoundAll =true;",
      "Map<Resource, ResourceRequest> reqMap = remoteRequests.get(hostName);",
      "if(reqMap !=null) {",
      "for(ResourceRequest req : reqMap.values()) {",
      "if(!ask.remove(req)) { foundAll =false;",
      "// if ask already sent to RM, we can try and overwrite it if possible.",
      "// send a new ask to RM with numContainers",
      "// specified for the blacklisted host to be 0.",
      "ResourceRequest zeroedRequest = BuilderUtils.newResourceRequest(req);",
      "zeroedRequest.setNumContainers(0);",
      "// to be sent to RM on next heartbeat",
      "ask.add(zeroedRequest);",
      "}",
      "}",
      "// if all requests were still in ask queue, we can remove this request",
      "if(foundAll) { remoteRequests.remove(hostName); }",
      "}",
      "}",
      "}else{nodeFailures.put(hostName, failures); }",
      "}",
      "",
      "It is called by event handler inRMContainerAllocator.java",
      "",
      "public synchronized voidhandle(ContainerAllocatorEvent event) {",
      "LOG.info(\"Processing the event \"+ event.toString());",
      "recalculateReduceSchedule=true;",
      "if(event.getType() == ContainerAllocator.EventType.CONTAINER_REQ) { …",
      "}else if( event.getType() == ContainerAllocator.EventType.CONTAINER_DEALLOCATE) {",
      "…",
      "}",
      "}else if( event.getType() == ContainerAllocator.EventType.CONTAINER_FAILED) {",
      "ContainerFailedEvent fEv = (ContainerFailedEvent) event;",
      "String host =getHost(fEv.getContMgrAddress());",
      "containerFailedOnHost(host);",
      "}",
      "}",
      "",
      "",
      "",
      "",
      ""
    ]
  }
}