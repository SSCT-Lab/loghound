{
  "p": [
    "HDFS-4404",
    "Create file failure when the machine of first attempted NameNode is down"
  ],
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "DFSClient (client-side) NameNode (server-side)"
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "Description in the bug report:",
        "test Environment: NN1,NN2,DN1,DN2,DN3",
        "machine1:NN1,DN1 machine2:NN2,DN2 machine3:DN3",
        "machine1 is down.",
        "(from the comments: “If you bring down a namenode and pretty much all clients that create files fail. That to me means file system appears to be down and not available”)",
        "The logs are from DFSClient.",
        "2013-01-12 09:51:21,248 DEBUG ipc.Client (Client.java:setupIOstreams(562)) - Connecting to /160.161.0.155:8020",
        "The ipc client on DFSClient side tries to connect NameNode(NN)1.",
        "",
        "2013-01-12 09:51:38,442 DEBUG ipc.Client (Client.java:close(932)) - closing ipc connection to vm2/160.161.0.155:8020: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]",
        "java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]",
        "at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)",
        "at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)",
        "at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)",
        "at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:474)",
        "at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:568)",
        "at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:217)",
        "at org.apache.hadoop.ipc.Client.getConnection(Client.java:1286)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1156)",
        "at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)",
        "at $Proxy9.create(Unknown Source)",
        "at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)",
        "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
        "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
        "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
        "at java.lang.reflect.Method.invoke(Method.java:597)",
        "at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)",
        "at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:84)",
        "at $Proxy10.create(Unknown Source)",
        "at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)",
        "at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)",
        "at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)",
        "at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)",
        "at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)",
        "at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)",
        "at test.TestLease.main(TestLease.java:45)",
        "Since machine1 is down(NN1 is running on it), the ipc connection times out and waits to connect again. From the call-stack, we know that this ipc communication is for creating file (FileSystem.create()).",
        "",
        "2013-01-12 09:51:38,443 DEBUG ipc.Client (Client.java:close(940)) - IPC Client (31594013) connection to /160.161.0.155:8020 from hdfs/hadoop@HADOOP.COM: closed",
        "IPC client still fails to connect NN1.",
        "",
        "2013-01-12 09:52:47,834 WARN retry.RetryInvocationHandler (RetryInvocationHandler.java:invoke(95)) - Exception while invoking class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create.Not retrying because the invoked method is not idempotent, and unable to determine whether it was invoked",
        "java.net.SocketTimeoutException: Call From szxy1x001833091/172.0.0.13 to vm2:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]; For more details see:http://wiki.apache.org/hadoop/SocketTimeout",
        "at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:743)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1180)",
        "at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)",
        "at $Proxy9.create(Unknown Source)",
        "at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)",
        "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
        "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
        "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
        "at java.lang.reflect.Method.invoke(Method.java:597)",
        "at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)",
        "at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:84)",
        "at $Proxy10.create(Unknown Source)",
        "at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)",
        "at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)",
        "at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)",
        "at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)",
        "at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)",
        "at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)",
        "at test.TestLease.main(TestLease.java:45)",
        "Caused by: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]",
        "at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)",
        "at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)",
        "at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)",
        "at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:474)",
        "at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:568)",
        "at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:217)",
        "at org.apache.hadoop.ipc.Client.getConnection(Client.java:1286)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1156)",
        "... 20 more",
        "java.net.SocketTimeoutException: Call From szxy1x001833091/172.0.0.13 to vm2:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]; For more details see:http://wiki.apache.org/hadoop/SocketTimeout",
        "at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:743)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1180)",
        "at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)",
        "at $Proxy9.create(Unknown Source)",
        "at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)",
        "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
        "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
        "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
        "at java.lang.reflect.Method.invoke(Method.java:597)",
        "at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)",
        "at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:84)",
        "at $Proxy10.create(Unknown Source)",
        "at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)",
        "at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)",
        "at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)",
        "at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)",
        "at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)",
        "at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)",
        "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)",
        "at test.TestLease.main(TestLease.java:45)",
        "Caused by: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]",
        "at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)",
        "at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)",
        "at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)",
        "at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:474)",
        "at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:568)",
        "at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:217)",
        "at org.apache.hadoop.ipc.Client.getConnection(Client.java:1286)",
        "at org.apache.hadoop.ipc.Client.call(Client.java:1156)",
        "... 20 more",
        "The call of create() from DFSClient fails finally due to the socketTimeout. Neither is create() tried again. Since “Not retrying because the invoked method is not idempotent, and unable to determine whether it was invoked”.",
        "",
        "2013-01-12 09:54:52,269 DEBUG ipc.Client (Client.java:stop(1021)) - Stopping client",
        "Stop a RPC client connection. A RPC client is closed only when its reference count becomes zero.",
        ""
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "(2.1) Some comments are added to the log.",
      "When DFSClient creates a file, it will connect NN1. Since machine1 which NN1 is running on is down, NN1 is also down. Since the function create() is marked as not idempotent, the create file operation will not retry, so it fails to create a file.",
      "(2.2) According to the configuration in this test, it provides two NameNodes. If the first one happens to be down, all the clients creating files will fail. This happens even though a second NameNode is active and providing service.",
      "(2.3) The log in this bug has shown the reason of the failure.",
      "(2.4) I think the focus of this bug is on the connection exception reported in the log. The developers discussed a lot about it, and the final patch is not about retry but the exception.",
      "Here is the explanation about why skipping the “retry”:",
      "The retry thing is certainly a bug, but in practice we don’t see this much, because almost all use cases involve doing one or more read-only (idempotent) ops before doing any non-idempotent ones. For example, when we tried to reproduce from the shell, we were unable to since “hadoop fs –put” will stat the file before creating it. Similarly, any MR task is likely to read some input before creating any output. These idempotent calls serve to find the correct active NN, and then the following non-idempotent ones succeed. This also serves to explain why we haven't seen many reports of it up to now - most clients will incidentally work just fine.",
      "",
      "The idea of the patch is based on this point: we need some way to communicate to the FailoverProxyProvider whether it was a failure to connect or a timeout in reading the response. In the current code, SocketTimeoutException is thrown in either case, so the layer which does failover can't know whether or not the call might have been invoked.",
      "And the detailed discussion upon this point is as follows:",
      "The crux of the issue here is that we want to communicate from the RPC call back to the caller whether the call was actually sent or not. Timeout on connect is one case where we failed before sending, but it's also possible that we'd get some kind of timeout during SASL (Java's Simple Authentication & Security Layer)negotiation, etc. For example, if one of the two NNs has lost contact with the KDC(Key Distribution Center) and won't authenticate people, we still want to failover.",
      "So, we'd like some more generic way to pass along the call status in the response beyond just making connect() timeouts throw ConnectException.",
      "This is tough to do, since the only way we can pass back information from the IPC.Client layer to the FailoverProxyProvider is via an exception, and critically, by making a new exception class which has the requisite info. The problem with making a new class, though, is that any callers who were depending on IPC calls throwing particular IOException subclasses like SocketTimeoutException or ConnectException will get broken (since they'd now end up with something like an IpcTransportException).",
      "We could handle the current specific case of timeout-on-connect by making a subclass of SocketTimeoutException like ConnectTimeoutException, and throw that. This would be compatible but not a complete solution. A more radical change would be to make a new IOException subclass like IpcTransportException, which is thrown for any case where the transport layer had a problem, with various subclasses for the different cases. This would be a bit difficult since it would be user-visible."
    ]
  },
  "(3) Root Cause": {
    "p": [
      "When DFSClient tries to connect NN1 to create a file, NN1 is shut down. Since “create()”is not idempotent, the operation will not be retried even if NN2 can take over."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "The patch can eliminate theexception effect.&& eliminate the exception itself (SocketTimeoutException will be caught and do retry)",
      "Make NetUtils.connect throw ConnectTimeoutException (subclass of SocketTimeoutException) on timeout. (The file ConnectTimeoutException.java is also newly created.)",
      "•hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/ConnectTimeoutException.java",
      "+public class ConnectTimeoutException extends SocketTimeoutException {",
      "+private static final long serialVersionUID = 1L;",
      "+",
      "+public ConnectTimeoutException(String msg) {",
      "+super(msg);",
      "+}",
      "+}",
      "• hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/NetUtils.java",
      "public static voidconnect(Socket socket,",
      "socket.bind(localAddr);",
      "}",
      "-if (ch == null) {",
      "-// let the default implementation handle it.",
      "-socket.connect(endpoint, timeout);",
      "-} else {",
      "-SocketIOWithTimeout.connect(ch, endpoint, timeout);",
      "+try {",
      "+if (ch == null) {",
      "+// let the default implementation handle it.",
      "+socket.connect(endpoint, timeout);",
      "+} else {",
      "+SocketIOWithTimeout.connect(ch, endpoint, timeout);",
      "+}",
      "+} catch (SocketTimeoutException ste) {",
      "+throw newConnectTimeoutException(ste.getMessage());",
      "}",
      "Then changed the FailoverOnNetworkException policy to check for this type.",
      "•hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/retry/RetryPolicies.java",
      "@@ -35,6 +35,7 @@",
      "import org.apache.commons.logging.LogFactory;",
      "import org.apache.hadoop.ipc.RemoteException;",
      "import org.apache.hadoop.ipc.StandbyException;",
      "+import org.apache.hadoop.net.ConnectTimeoutException;",
      "/**",
      "* <p>",
      "@@ -543,6 +544,7 @@ public RetryActionshouldRetry(Exception e, int retries,",
      "e instanceof NoRouteToHostException ||",
      "e instanceof UnknownHostException ||",
      "e instanceof StandbyException ||",
      "+e instanceof ConnectTimeoutException ||",
      "isWrappedStandbyException(e)) {",
      "return new RetryAction(",
      "RetryAction.RetryDecision.FAILOVER_AND_RETRY,",
      "",
      "Also change the NetUtils.wrapException code so that when wrapping, it would re-throw with the correct subclass instead of recreating the superclass. (it's necessary because, now that we construct a subclass of SocketTimeoutException, it would have caused wrapWithException to convert it back to the superclass – the exception is still instanceof SocketTimeoutException, so the rethrow wouldn't preserve the right class. The new rethrow method preserves the right class.)",
      "•hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/NetUtils.java",
      "public static IOExceptionwrapException(final String destHost,",
      "+ see(\"BindException\"));",
      "} else if (exception instanceof ConnectException) {",
      "// connection refused; include the host:port in the error",
      "-return (ConnectException) new ConnectException(",
      "+returnwrapWithMessage(exception,",
      "\"Call From \"",
      "+ localHost",
      "+ \" to \"",
      "@@ -729,32 +734,28 @@ public static IOException wrapException(final String destHost,",
      "+ \" failed on connection exception: \"",
      "+ exception",
      "+ \";\"",
      "-+ see(\"ConnectionRefused\"))",
      "-.initCause(exception);",
      "++ see(\"ConnectionRefused\"));",
      "} else if (exception instanceof UnknownHostException) {",
      "-return (UnknownHostException) new UnknownHostException(",
      "+returnwrapWithMessage(exception,",
      "\"Invalid host name: \"",
      "+ getHostDetailsAsString(destHost, destPort, localHost)",
      "+ exception",
      "+ \";\"",
      "-+ see(\"UnknownHost\"))",
      "-.initCause(exception);",
      "++ see(\"UnknownHost\"));",
      "} else if (exception instanceof SocketTimeoutException) {",
      "-return (SocketTimeoutException) new SocketTimeoutException(",
      "+returnwrapWithMessage(exception,",
      "\"Call From \"",
      "+ localHost + \" to \" + destHost + \":\" + destPort",
      "+ \" failed on socket timeout exception: \" + exception",
      "+ \";\"",
      "-+ see(\"SocketTimeout\"))",
      "-.initCause(exception);",
      "++ see(\"SocketTimeout\"));",
      "} else if (exception instanceof NoRouteToHostException) {",
      "-return (NoRouteToHostException) new NoRouteToHostException(",
      "+returnwrapWithMessage(exception,",
      "\"No Route to Host from \"",
      "+ localHost + \" to \" + destHost + \":\" + destPort",
      "+ \" failed on socket timeout exception: \" + exception",
      "+ \";\"",
      "-+ see(\"NoRouteToHost\"))",
      "-.initCause(exception);",
      "++ see(\"NoRouteToHost\"));",
      "}",
      "else {",
      "return (IOException) new IOException(\"Failed on local exception: \"",
      "",
      "@@ -769,6 +770,21 @@ public static IOException wrapException(final String destHost,",
      "private static String see(final String entry) {",
      "return FOR_MORE_DETAILS_SEE + HADOOP_WIKI + entry;",
      "}",
      "+",
      "+@SuppressWarnings(\"unchecked\")",
      "+private static <T extends IOException> TwrapWithMessage(",
      "+T exception, String msg) {",
      "+Class<? extends Throwable> clazz = exception.getClass();",
      "+try {",
      "+Constructor<? extends Throwable> ctor = clazz.getConstructor(String.class);",
      "+Throwable t = ctor.newInstance(msg);",
      "+return (T)(t.initCause(exception));",
      "+} catch (Throwable e) {",
      "+LOG.warn(\"Unable to wrap exception of type \" +",
      "+clazz + \": it has no (String) constructor\", e);",
      "+return exception;+}",
      "+}",
      ""
    ]
  },
  "(5) How many nodes are involved in the patch": {
    "p": [
      "The patch is in common utility."
    ]
  },
  "(6) Code Snippets": {
    "p": [
      "From the call-stack, we know that the exception handle is related to",
      "“org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:84)”.",
      "In function RetryInvocationHandler.invoke(), functionshouldRetry() is called, which is related to “how the same exception is handled differently (i.e., retry is conducted at the exception handler) for idempotent operation”.",
      "",
      "publicObjectinvoke(Object proxy, Method method, Object[] args)throwsThrowable {RetryPolicy policy =methodNameToPolicyMap.get(method.getName());",
      "if(policy ==null) { policy =defaultPolicy;",
      "}",
      "// The number of times this method invocation has been failed over.intinvocationFailoverCount =0;",
      "intretries =0;",
      "while(true) {// The number of times this invocation handler has ever been failed over,before this method invocation attempt. Used to prevent concurrent failed method invocations from triggering multiple failover attempts.longinvocationAttemptFailoverCount;synchronized(proxyProvider) {invocationAttemptFailoverCount =proxyProviderFailoverCount;",
      "}",
      "try{Object ret = invokeMethod(method, args);invokeMethod() will execute “create()” via RPChasMadeASuccessfulCall=true;",
      "returnret;",
      "}catch(Exception e) {booleanisMethodIdempotent =proxyProvider.getInterface().getMethod(method.getName(), method.getParameterTypes()).isAnnotationPresent(Idempotent.class);RetryAction action =policy.shouldRetry(e, retries++, invocationFailoverCount, isMethodIdempotent);shouldRetry() is called to determine the retry action. In this bug, the return value of shouldRetry() is",
      "return newRetryAction(RetryAction.RetryDecision.FAIL,0,\"the invoked method is not idempotent, and unable to determine \"+\"whether it was invoked\");",
      "if(action.action== RetryAction.RetryDecision.FAIL) {if(action.reason!=null) {LOG.warn(\"Exception while invoking \"+currentProxy.getClass() +\".\"+ method.getName() +\". Not retrying because \"+ action.reason, e);（This WARN log entry is printed in the log)}",
      "throwe;}else{（If the operation is idempotent, it will return RetryAction.FAILOVER_AND_RETRY,",
      "so executing “else”.The method will be retried in the next run within the while loop)",
      "// retry or failover// avoid logging the failover if this is the first call on this",
      "// proxy object, and we successfully achieve the failover without// any flip-floppingbooleanworthLogging = !(invocationFailoverCount ==0&& !hasMadeASuccessfulCall);worthLogging |=LOG.isDebugEnabled();",
      "if(action.action== RetryAction.RetryDecision.FAILOVER_AND_RETRY&& worthLogging) {String msg =\"Exception while invoking \"+ method.getName() +\" of class \"+currentProxy.getClass().getSimpleName();if(invocationFailoverCount >0) {msg +=\" after \"+ invocationFailoverCount +\" fail over attempts\"}",
      "msg +=\". Trying to fail over \"+formatSleepMessage(action.delayMillis);if(LOG.isDebugEnabled()) {LOG.debug(msg, e);}else{LOG.warn(msg); }}else{if(LOG.isDebugEnabled()) {",
      "LOG.debug(\"Exception while invoking \"+ method.getName() +\" of class \"+currentProxy.getClass().getSimpleName() +\". Retrying \"+formatSleepMessage(action.delayMillis), e);",
      "}}if(action.delayMillis>0) {",
      "ThreadUtil.sleepAtLeastIgnoreInterrupts(action.delayMillis);}",
      "if(action.action== RetryAction.RetryDecision.FAILOVER_AND_RETRY) {// Make sure that concurrent failed method invocations only cause a// single actual fail over.synchronized(proxyProvider) {",
      "if(invocationAttemptFailoverCount ==proxyProviderFailoverCount) {proxyProvider.performFailover(currentProxy);proxyProviderFailoverCount++;currentProxy=proxyProvider.getProxy();}else{LOG.warn(\"A failover has occurred since the start of this method\"+\" invocation attempt.\");}}",
      "invocationFailoverCount++;",
      "}}}}//while}",
      "",
      "Method shouldRetry() is in RetryPolicies.java",
      "",
      "static classFailoverOnNetworkExceptionRetryimplementsRetryPolicy {",
      "privateRetryPolicyfallbackPolicy;private intmaxFailovers;private longdelayMillis;private longmaxDelayBase;…@OverridepublicRetryActionshouldRetry(Exception e,intretries,intfailovers,booleanisMethodIdempotent)throwsException {",
      "if(failovers >=maxFailovers) {return newRetryAction(RetryAction.RetryDecision.FAIL,0,n\"failovers (\"+ failovers +\") exceeded maximum allowed (\"+maxFailovers+\")\");}",
      "if(einstanceofConnectException ||einstanceofNoRouteToHostException ||einstanceofUnknownHostException ||einstanceofStandbyException ||+e instanceofConnectTimeoutException||（In the patch, a new exception case “ConnectTimeoutException” is added, so it will retry whether the method is idemponent or not.）",
      "isWrappedStandbyException(e)) {return newRetryAction(RetryAction.RetryDecision.FAILOVER_AND_RETRY,// retry immediately if this is our first failover, sleep otherwisefailovers ==0?0:calculateExponentialTime(delayMillis, failovers,maxDelayBase));",
      "}else if(einstanceofSocketException ||(einstanceofIOException && !(einstanceofRemoteException))) {（In this bug, the condition in green region is true)",
      "if(isMethodIdempotent) {returnRetryAction.FAILOVER_AND_RETRY;}else{return newRetryAction(RetryAction.RetryDecision.FAIL,0,\"the invoked method is not idempotent, and unable to determine \"+\"whether it was invoked\");}}else{returnfallbackPolicy.shouldRetry(e, retries, failovers, isMethodIdempotent);",
      "}}",
      "}",
      ""
    ]
  }
}