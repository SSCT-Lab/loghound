{
  "p": [
    "HDFS-5671"
  ],
  "Fix socket leak in DFSInputStream#getBlockReader": {},
  "(1) Log information": {
    "(1.1) Roles in this case": {
      "p": [
        "RegionServer (client-side) DataNode (server-side)"
      ]
    },
    "(1.2) Symptoms": {
      "p": [
        "When executing the command: lsof -i TCP:1004| grep -c CLOSE_WAIT",
        "Output: 18235",
        "The result shows that so many connections using TCP port 1004 are not closed.",
        "The CLOSE_WAIT status means that the other side has initiated a connection close, but the application on the local side has not yet closed the socket.",
        "The logs are from both RegionServer and DataNode:",
        "(RegionServer is the component in HBase. HBase can provide low-latency random reads and writes on top of HDFS.)",
        "RegionServer (DFSClient):",
        "2013-12-13 15:48:31,474 INFO org.apache.hadoop.hdfs.DFSClient: Will fetch a new access token and retry, access token was invalid when connecting to /192.168.2.27:1004: org.apache.hadoop.hdfs.security.token.block.InvalidBlockTokenException: Got access token error for OP_READ_BLOCK, self=/192.168.2.27:56975, remote=/192.168.2.27:1004, for file /hbase/XXXX/b50bf1b95c9242cdd242dc4e6549bc90/raw/d59819ebe5574c79a5d1cf13a733d2ed, for pool BP-621472495-192.168.2.25-1375176775166 block -882505774551713967_11426277",
        "Datanode:",
        "2013-12-13 15:48:31,474 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: dn2:1004:DataXceiver error processing READ_BLOCK operation src: /192.168.2.27:56975 dest: /192.168.2.27:1004",
        "org.apache.hadoop.security.token.SecretManager$InvalidToken: Block token with block_token_identifier (expiryDate=1386914547771, keyId=2020397153, userId=hbase, blockPoolId=BP-621472495-192.168.2.25-1375176775166, blockId=-882505774551713967, access modes=[READ]) is expired.",
        "at org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.checkAccess(BlockTokenSecretManager.java)",
        "at org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.checkAccess(BlockTokenSecretManager.java)",
        "at org.apache.hadoop.hdfs.security.token.block.BlockPoolTokenSecretManager.checkAccess(BlockPoolTokenSecretManager.java)",
        "at org.apache.hadoop.hdfs.server.datanode.DataXceiver.checkAccess(DataXceiver.java)",
        "at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java)",
        "at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java)",
        "at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java)",
        "at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java)",
        "at java.lang.Thread.run(Thread.java)",
        "There is an error when DataNode “dn2”(192.168.2.27:1004) processes the operation “READ_BLOCK” from DFSClient (192.168.2.27:56975), due to invalid token.",
        ""
      ]
    }
  },
  "(2) How to figure out the root cause based on logs": {
    "p": [
      "(2.1) Based on the statement contained in the DFSClient-side log:“2013-12-13 15:48:31,474 INFO org.apache.hadoop.hdfs.DFSClient:Will fetch a new access token and retry, access token was invalid when connecting to/192.168.2.27:1004”, we can locate the source code where this information is printed. It is in function blockSeekTo() (DFSInputStream.java).",
      "The exception occurs here is InvalidBlockTokenException, which extends from IOException.",
      "(2.2) Since there is no call stack in client-side log, we need to find the place where the exception occurs.",
      "We can determine function getBlockReader() throws IOException, Because only getBlockReader() can throw IOException in the try block.",
      "private synchronizedDatanodeInfoblockSeekTo(longtarget)throwsIOException {…// Connect to best DataNode for desired Block, with potential offsetDatanodeInfo chosenNode =null;",
      "intrefetchToken =1;// only need to get a new access token onceintrefetchEncryptionKey =1;// only need to get a new encryption key once",
      "booleanconnectFailedOnce =false;",
      "while(true) {// Compute desired block…try{ExtendedBlock blk = targetBlock.getBlock();Token<BlockTokenIdentifier> accessToken = targetBlock.getBlockToken();",
      "blockReader=getBlockReader(targetAddr, chosenNode,src, blk,accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,",
      "buffersize,verifyChecksum,dfsClient.clientName);if(connectFailedOnce) {DFSClient.LOG.info(\"Successfully connected to \"+ targetAddr +\" for \"+ blk);}",
      "returnchosenNode;",
      "}catch(AccessControlException ex) {",
      "DFSClient.LOG.warn(\"Short circuit access failed \"+ ex);dfsClient.disableLegacyBlockReaderLocal();continue;}catch(IOExceptionex) {",
      "if(exinstanceofInvalidEncryptionKeyException && refetchEncryptionKey >0) {DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"+\"encryption key was invalid when connecting to\"+ targetAddr +\" : \"+ ex);// The encryption key used is invalid.refetchEncryptionKey--;",
      "dfsClient.clearDataEncryptionKey();",
      "}else if(exinstanceofInvalidBlockTokenException&& refetchToken >0) {DFSClient.LOG.info(\"Will fetch a new access token and retry, \"+\"access token was invalid when connecting to \"+ targetAddr +\" : \"+ ex);This log is printed in DFSClient",
      "refetchToken--;fetchBlockAt(target);}else{connectFailedOnce =true;DFSClient.LOG.warn(\"Failed to connect to \"+ targetAddr +\" for block\"+\", add to deadNodes and continue. \"+ ex, ex);",
      "// Put chosen node into dead list, continueaddToDeadNodes(chosenNode);}}}// While}",
      "(2.3) In function getBlockReader(), there are several try-catch blocks. Since the IOException can finally be thrown out, we can infer that the last two statements in this function may throw the IOException (i.e., newTcpPeer() or newBlockReader() ).",
      "protectedBlockReadergetBlockReader(InetSocketAddress dnAddr,DatanodeInfo chosenNode, String file, ExtendedBlock block,Token<BlockTokenIdentifier> blockToken,longstartOffset,longlen,intbufferSize,booleanverifyChecksum, String clientName)throwsIOException {…",
      "// Look for cached domain peers.…for(; cacheTries < nCachedConnRetry; ++cacheTries) {Peer peer =peerCache.get(chosenNode,true);if(peer ==null)break;try{…",
      "returnreader;}catch(IOException ex) {",
      "DFSClient.LOG.debug(\"Error making BlockReader with DomainSocket. \"+\"Closing stale \"+ peer, ex);",
      "}finally{",
      "if(reader ==null) { IOUtils.closeQuietly(peer); }}",
      "}",
      "// Try to create a DomainPeer.DomainSocket domSock = dsFactory.create(dnAddr,this);if(domSock !=null) {Peer peer =newDomainPeer(domSock);try{…returnreader;}catch(IOException e) {DFSClient.LOG.warn(\"failed to connect to \"+ domSock, e);}finally{if(reader ==null) {…IOUtils.closeQuietly(peer);",
      "}}}",
      "// Look for cached peers.…try{",
      "reader = BlockReaderFactory.newBlockReader(…);returnreader;",
      "}catch(IOException ex) {",
      "DFSClient.LOG.debug(\"Error making BlockReader. Closing stale \"+ peer, ex);}finally{if(reader ==null) { IOUtils.closeQuietly(peer); }}}if(tcpReadsDisabledForTesting) {throw newIOException(\"TCP reads are disabled.\");}// Try to create a new remote peer.Peer peer = newTcpPeer(dnAddr);-returnBlockReaderFactory.newBlockReader(-dfsClient.getConf(), file, block, blockToken, startOffset,-len, verifyChecksum, clientName, peer, chosenNode,-dsFactory,peerCache,fileInputStreamCache,false,-cachingStrategy);",
      "+try {",
      "+reader = BlockReaderFactory.newBlockReader(dfsClient.getConf(), file,",
      "+block, blockToken, startOffset, len, verifyChecksum, clientName,",
      "+peer, chosenNode, dsFactory, peerCache, fileInputStreamCache, false,",
      "+curCachingStrategy);",
      "+return reader;",
      "+} catch (IOException ex) {",
      "+DFSClient.LOG.debug(",
      "+\"Exception while getting block reader, closing stale \" + peer, ex);",
      "+throw ex;",
      "+} finally {",
      "+if (reader == null) {",
      "+IOUtils.closeQuietly(peer);",
      "+}",
      "+}",
      "}",
      "",
      "(2.4) Then according to the following call relation, InvalidBlockTokenException occurs in checkSuccess().",
      "",
      "static voidcheckSuccess(BlockOpResponseProto status, Peer peer,ExtendedBlock block, String file)throwsIOException {if(status.getStatus() != Status.SUCCESS) {",
      "if(status.getStatus() == Status.ERROR_ACCESS_TOKEN) {throw newInvalidBlockTokenException(\"Got access token error for OP_READ_BLOCK, self=\"+ peer.getLocalAddressString() +\", remote=\"+ peer.getRemoteAddressString() +\", for file \"+ file",
      "+\", for pool \"+ block.getBlockPoolId() +\" block \"+ block.getBlockId() +\"_\"+ block.getGenerationStamp());",
      "}else{throw newIOException(\"Got error for OP_READ_BLOCK, self=\"+ peer.getLocalAddressString() +\", remote=\"+ peer.getRemoteAddressString() +\", for file \"+ file+\", for pool \"+ block.getBlockPoolId() +\" block \"+ block.getBlockId() +\"_\"+ block.getGenerationStamp());}}}",
      "",
      "(2.5) In DataNode (server-side), based on the call stack, we can locate the source code where the exception happens. The top-most frame in the call stack “BlockTokenSecretManager.checkAccess” throws “InvalidToken(extends from IOException)” layer by layer and the exception is finally thrown by function processOp() as IOException in DataXceiver.run(), then caught. The related code is as follows:",
      "DataXceiver:Thread for processing incoming/outgoing data stream.",
      "@Override",
      "public voidrun(){",
      "intopsProcessed =0;",
      "Op op =null;",
      "dataXceiverServer.addPeer(peer);",
      "try{…",
      "do{ updateCurrentThreadName(\"Waiting for operation #\"+ (opsProcessed +1));",
      "…",
      "opStartTime=now();",
      "processOp(op);",
      "++opsProcessed;",
      "}while(!peer.isClosed() &&dnConf.socketKeepaliveTimeout>0);",
      "}catch(Throwable t) {",
      "LOG.error(datanode.getDisplayName() +\":DataXceiver error processing \"+",
      "((op ==null) ?\"unknown\": op.name()) +\" operation \"+\" src: \"+remoteAddress+\" dest: \"+localAddress, t);",
      "}finally{",
      "if(LOG.isDebugEnabled()) {",
      "LOG.debug(datanode.getDisplayName() +\":Number of active connections is: \"+datanode.getXceiverCount());",
      "}",
      "updateCurrentThreadName(\"Cleaning up\");",
      "dataXceiverServer.closePeer(peer);",
      "IOUtils.closeStream(in);",
      "}",
      "}",
      "We see that after the IOException is caught by “catch(Throwable t)”, the peer will be closed in finally block in the server side.",
      "However, in the client side, when IOException is finally caught in (2.2)blockSeekTo(), there is no operation to close the connection. So it becomes CLOSE_WAIT."
    ]
  },
  "(3) Root Cause": {
    "p": [
      "When DataNode gets InvalidToken exception during the read block operation, it will close the connection, but in the client side, when Region Server catches the IOException in blockSeekTo(), the connection is not closed, and it becomes CLOSE_WAIT."
    ]
  },
  "(4) Fixing Method": {
    "p": [
      "In function getBlockReader(), add try-catch around the return value.",
      "If it fails tonewBlockReader(), throw the exception as well as close the connection.",
      "•/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "// Try to create a new remote peer.",
      "Peer peer = newTcpPeer(dnAddr);",
      "-return BlockReaderFactory.newBlockReader(",
      "-dfsClient.getConf(), file, block, blockToken, startOffset,",
      "-len, verifyChecksum, clientName, peer, chosenNode,",
      "-dsFactory, peerCache, fileInputStreamCache, false,",
      "-curCachingStrategy);",
      "+try {",
      "+reader = BlockReaderFactory.newBlockReader(dfsClient.getConf(), file,",
      "+block, blockToken, startOffset, len, verifyChecksum, clientName,",
      "+peer, chosenNode, dsFactory, peerCache, fileInputStreamCache, false,",
      "+curCachingStrategy);",
      "+return reader;",
      "+} catch (IOException ex) {",
      "+DFSClient.LOG.debug(",
      "+\"Exception while getting block reader, closing stale \" + peer, ex);",
      "+throw ex;",
      "+} finally {",
      "+if (reader == null) {",
      "+IOUtils.closeQuietly(peer);",
      "+}",
      "+}",
      "}",
      "The patch fixes the effect brought by the InvalidTokenException."
    ]
  },
  "(5) How many nodes are involved in the patch": {
    "p": [
      "The patch will be applied in DFSClient.",
      "Function getBlockReader() is in DFSInputStream.java, not on the call stack. (no client-side callstack is provided in this bug)."
    ]
  }
}